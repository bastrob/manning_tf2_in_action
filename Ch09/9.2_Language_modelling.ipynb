{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import requests\n",
    "print(tf.__version__)\n",
    "import zipfile\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.models as models\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from PIL import Image\n",
    "from PIL.PngImagePlugin import PngImageFile\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from functools import partial\n",
    "import nltk\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "random_seed=4321\n",
    "fix_random_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tar file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "# Downloading the data\n",
    "# http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data', 'lm','CBTest.tgz')):\n",
    "    url = \"http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists(os.path.join('data','lm')):\n",
    "        os.mkdir(os.path.join('data','lm'))\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data', 'lm', 'CBTest.tgz'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "          \n",
    "else:\n",
    "    print(\"The tar file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'lm', 'CBTest')):\n",
    "    # Write to a file\n",
    "    tarf = tarfile.open(os.path.join(\"data\",\"lm\",\"CBTest.tgz\"))\n",
    "    tarf.extractall(os.path.join(\"data\",\"lm\"))  \n",
    "else:\n",
    "    print(\"The extracted data already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    stories = []\n",
    "\n",
    "    with open(path, 'r') as f:    \n",
    "        s = []\n",
    "        start_capture = False    \n",
    "        for row in f:\n",
    "\n",
    "            if start_capture:\n",
    "                s.append(row)\n",
    "\n",
    "            if row.startswith(\"_BOOK_TITLE_\"):\n",
    "                if len(s)>0:\n",
    "                    stories.append(' '.join(s).lower())            \n",
    "                s = []\n",
    "                start_capture=True            \n",
    "\n",
    "    if len(s)>0:\n",
    "        stories.append(' '.join(s).lower())  \n",
    "    \n",
    "    return stories\n",
    "\n",
    "stories = read_data(os.path.join('data','lm','CBTest','data','cbt_train.txt'))\n",
    "val_stories = read_data(os.path.join('data','lm','CBTest','data','cbt_valid.txt'))\n",
    "test_stories = read_data(os.path.join('data','lm','CBTest','data','cbt_test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 98 stories (train)\n",
      "Collected 5 stories (valid)\n",
      "Collected 5 stories (test)\n",
      "chapter i. -lcb- chapter heading picture : p1.jpg -rcb- how the fairies were not invited to court .\n",
      "\n",
      "\n",
      " a tale of the tontlawald long , long ago there stood in the midst of a country covered with lakes a \n"
     ]
    }
   ],
   "source": [
    "print(\"Collected {} stories (train)\".format(len(stories)))\n",
    "print(\"Collected {} stories (valid)\".format(len(val_stories)))\n",
    "print(\"Collected {} stories (test)\".format(len(test_stories)))\n",
    "print(stories[0][:100])\n",
    "print('\\n', stories[10][:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: I like chocolates\n",
      "\t1-grams: ['I', ' ', 'l', 'i', 'k', 'e', ' ', 'c', 'h', 'o', 'c', 'o', 'l', 'a', 't', 'e', 's']\n",
      "\t2-grams: ['I ', 'li', 'ke', ' c', 'ho', 'co', 'la', 'te', 's']\n",
      "\t3-grams: ['I l', 'ike', ' ch', 'oco', 'lat', 'es']\n",
      "e     455292\n",
      " t    344971\n",
      "he    310539\n",
      "d     308390\n",
      "th    284425\n",
      " a    268496\n",
      "t     257788\n",
      "s     227961\n",
      " h    192544\n",
      " s    182830\n",
      "dtype: int64\n",
      "\n",
      "Median: 136.5\n",
      "\n",
      "count      1074.000000\n",
      "mean      12106.919926\n",
      "std       36358.817692\n",
      "min           1.000000\n",
      "25%           5.000000\n",
      "50%         136.500000\n",
      "75%        6406.750000\n",
      "90%       34184.600000\n",
      "max      455292.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "def ngrams(text, n):\n",
    "    return [text[i:i+n] for i in range(0,len(text),n)]\n",
    "\n",
    "test_string = \"I like chocolates\"\n",
    "print(\"Original: {}\".format(test_string))\n",
    "for i in list(range(3)):\n",
    "    print(\"\\t{}-grams: {}\".format(i+1, ngrams(test_string, i+1)))\n",
    "    \n",
    "text = chain(*[ngrams(s, 2) for s in stories])\n",
    "cnt = Counter(text)\n",
    "freq_df = pd.Series(list(cnt.values()), index=list(cnt.keys())).sort_values(ascending=False)\n",
    "print(freq_df.head(n=10))\n",
    "print(\"\\nMedian: {}\\n\".format(freq_df.median()))\n",
    "print(freq_df.describe(percentiles=[0.25,0.5,0.75,0.9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 735\n"
     ]
    }
   ],
   "source": [
    "n_vocab = (freq_df>=10).sum()\n",
    "print(\"Size of vocabulary: {}\".format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "n = 2 #ngram length\n",
    "tokenizer = Tokenizer(num_words=n_vocab, oov_token='unk', lower=False)\n",
    "train_ngram_stories = [ngrams(s,n) for s in stories]\n",
    "tokenizer.fit_on_texts(train_ngram_stories)\n",
    "\n",
    "train_data_seq = tokenizer.texts_to_sequences(train_ngram_stories)\n",
    "\n",
    "val_ngram_stories = [ngrams(s,n) for s in val_stories]\n",
    "val_data_seq = tokenizer.texts_to_sequences(val_ngram_stories)\n",
    "\n",
    "test_ngram_stories = [ngrams(s,n) for s in test_stories]\n",
    "test_data_seq = tokenizer.texts_to_sequences(test_ngram_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_pipeline(data_seq, n_seq, batch_size=64, stride=1, shuffle=True):\n",
    "        \n",
    "    text_ds = tf.data.Dataset.from_tensor_slices(tf.ragged.constant(data_seq)) # tf.ragged.constant(data_seq)\n",
    "    \n",
    "    if shuffle:\n",
    "        text_ds = text_ds.shuffle(buffer_size=len(data_seq)//2)\n",
    "        \n",
    "    text_ds = text_ds.flat_map(lambda x: tf.data.Dataset.from_tensor_slices(x).window(n_seq+1,shift=stride)    )\n",
    "    text_ds = text_ds.flat_map(lambda window: window.batch(n_seq+1, drop_remainder=True))\n",
    "    \n",
    "    #text_ds = text_ds.unbatch()\n",
    "    \n",
    "    if shuffle:\n",
    "        text_ds = text_ds.shuffle(buffer_size=10*batch_size)\n",
    "    \n",
    "    text_ds = text_ds.batch(batch_size)\n",
    "    text_ds = tf.data.Dataset.zip(text_ds.map(lambda x: (x[:,:-1], x[:, 1:]))).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return text_ds\n",
    "    #return x,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
      "array([[ 8, 12,  3, 12,  2],\n",
      "       [11,  2,  9,  2,  4],\n",
      "       [ 4,  3, 11,  2,  9],\n",
      "       [28,  3, 10,  4,  2],\n",
      "       [12,  2, 10, 14, 16],\n",
      "       [16, 16,  3, 11,  2]], dtype=int32)>, <tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
      "array([[12,  3, 12,  2,  5],\n",
      "       [ 2,  9,  2,  4,  7],\n",
      "       [ 3, 11,  2,  9,  2],\n",
      "       [ 3, 10,  4,  2,  9],\n",
      "       [ 2, 10, 14, 16, 16],\n",
      "       [16,  3, 11,  2,  9]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
      "array([[29, 29,  2,  7,  5],\n",
      "       [ 2,  4,  7,  3,  2],\n",
      "       [ 8,  3,  2, 21,  2],\n",
      "       [ 2, 20,  7,  5,  8],\n",
      "       [14, 16, 16,  3, 11],\n",
      "       [23,  4,  3, 11,  2]], dtype=int32)>, <tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
      "array([[29,  2,  7,  5, 11],\n",
      "       [ 4,  7,  3,  2, 10],\n",
      "       [ 3,  2, 21,  2, 26],\n",
      "       [20,  7,  5,  8, 17],\n",
      "       [16, 16,  3, 11,  2],\n",
      "       [ 4,  3, 11,  2,  9]], dtype=int32)>)\n",
      "(<tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
      "array([[12,  2,  5,  8, 12],\n",
      "       [11,  2,  9, 10,  2],\n",
      "       [21,  2, 26, 26,  2],\n",
      "       [ 7,  5,  8, 17,  3],\n",
      "       [ 3,  8, 12,  3, 12],\n",
      "       [17,  3,  2, 29, 29]], dtype=int32)>, <tf.Tensor: shape=(6, 5), dtype=int32, numpy=\n",
      "array([[ 2,  5,  8, 12,  2],\n",
      "       [ 2,  9, 10,  2, 17],\n",
      "       [ 2, 26, 26,  2, 36],\n",
      "       [ 5,  8, 17,  3,  2],\n",
      "       [ 8, 12,  3, 12,  2],\n",
      "       [ 3,  2, 29, 29,  2]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "ds = get_tf_pipeline(train_data_seq, 5, batch_size=6)\n",
    "\n",
    "for a in ds.take(3):\n",
    "\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1708.02182.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 512)         376832    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 1024)        4724736   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 512)         524800    \n",
      "_________________________________________________________________\n",
      "final_out (Dense)            (None, None, 735)         377055    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, None, 735)         0         \n",
      "=================================================================\n",
      "Total params: 6,003,423\n",
      "Trainable params: 6,003,423\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# https://gist.github.com/Gregorgeous/dbad1ec22efc250c76354d949a13cec3\n",
    "class PerplexityMetric(tf.keras.metrics.Mean):\n",
    "    \"\"\"\n",
    "    USAGE NOTICE: this metric accepts only logits for now (i.e. expect the same behaviour as from tf.keras.losses.SparseCategoricalCrossentropy with the a provided argument \"from_logits=True\", \n",
    "\t\there the same loss is used with \"from_logits=True\" enforced so you need to provide it in such a format)\n",
    "    METRIC DESCRIPTION:\n",
    "    Popular metric for evaluating language modelling architectures.\n",
    "    More info: http://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf.\n",
    "    DISCLAIMER: Original function created by Kirill Mavreshko in https://github.com/kpot/keras-transformer/blob/b9d4e76c535c0c62cadc73e37416e4dc18b635ca/example/run_gpt.py#L106. \n",
    "    My \"contribution\": I converted Kirill method's logic (and added a padding masking to to it) into this new Tensorflow 2.0 way of doing things via a stateful \"Metric\" object. This required making the metric a fully-fledged object by subclassing the Metric class. \n",
    "    \"\"\"\n",
    "    def __init__(self, name='perplexity', **kwargs):\n",
    "      super(PerplexityMetric, self).__init__(name=name, **kwargs)\n",
    "      self.cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "    def _calculate_perplexity(self, real, pred):\n",
    "      # The next 4 lines zero-out the padding from loss calculations, \n",
    "      # this follows the logic from: https://www.tensorflow.org/beta/tutorials/text/transformer#loss_and_metrics \t\t\t\n",
    "      #mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "      loss_ = self.cross_entropy(real, pred)\n",
    "      #print(loss_.shape)\n",
    "      #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "      #loss_ *= mask\n",
    "      # Calculating the perplexity steps: \n",
    "      step1 = K.mean(loss_, axis=-1)\n",
    "      step2 = K.exp(step1)\n",
    "      perplexity = K.mean(step2)\n",
    "      #perplexity = K.exp(K.mean(loss_))\n",
    "      \n",
    "      return perplexity \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):            \n",
    "      perplexity = self._calculate_perplexity(y_true, y_pred)\n",
    "      # Remember self.perplexity is a tensor (tf.Variable), so using simply \"self.perplexity = perplexity\" will result in error because of mixing EagerTensor and Graph operations \n",
    "      super(PerplexityMetric, self).update_state(perplexity)\n",
    "\n",
    "        \n",
    "K.clear_session()\n",
    "n_seq=100\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_vocab+1, output_dim=512, input_shape=(None,)),\n",
    "    # Defining an LSTM layer\n",
    "    tf.keras.layers.GRU(1024, return_state=False, return_sequences=True),\n",
    "    #tf.keras.layers.GRU(512, return_state=False, return_sequences=True),\n",
    "    # Defining a Dense layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    #tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.8)),\n",
    "    #tf.keras.layers.Dense(512, activation='relu'),\n",
    "    #tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.8)),\n",
    "    tf.keras.layers.Dense(n_vocab, name='final_out'),\n",
    "    tf.keras.layers.Activation(activation='softmax')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', PerplexityMetric()]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2082006, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "p = PerplexityMetric()\n",
    "true = [[0, 1,2],[0, 1,2]]\n",
    "pred = [[[0.9, 0.1, 0.0], [0.3, 0.7, 0.0], [0.0, 0.1, 0.9]],[[0.9, 0.1, 0.0], [0.3, 0.7, 0.0], [0.0, 0.1, 0.9]]]\n",
    "p.update_state(true, pred)\n",
    "print(p.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU got to around 35% accuracy and 39 validation perplexity\n",
    "\n",
    "5873 steps 128 batch size 50 stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using metric=val_perplexity and mode=min for EarlyStopping\n",
      "Epoch 1/50\n",
      "2936/2936 [==============================] - 341s 116ms/step - loss: 2.3857 - accuracy: 0.4313 - perplexity: 15.2877 - val_loss: 2.4790 - val_accuracy: 0.4113 - val_perplexity: 12.6962 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2936/2936 [==============================] - 343s 117ms/step - loss: 2.0692 - accuracy: 0.4853 - perplexity: 8.4284 - val_loss: 2.4818 - val_accuracy: 0.4150 - val_perplexity: 12.8089 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2936/2936 [==============================] - 344s 117ms/step - loss: 2.0456 - accuracy: 0.4889 - perplexity: 8.2086 - val_loss: 2.4728 - val_accuracy: 0.4130 - val_perplexity: 12.6940 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2936/2936 [==============================] - 345s 117ms/step - loss: 2.0390 - accuracy: 0.4891 - perplexity: 8.1284 - val_loss: 2.4252 - val_accuracy: 0.4215 - val_perplexity: 12.0610 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2936/2936 [==============================] - 347s 118ms/step - loss: 2.0380 - accuracy: 0.4885 - perplexity: 8.0946 - val_loss: 2.4085 - val_accuracy: 0.4273 - val_perplexity: 11.9038 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2936/2936 [==============================] - 345s 118ms/step - loss: 2.0324 - accuracy: 0.4891 - perplexity: 8.0472 - val_loss: 2.4290 - val_accuracy: 0.4226 - val_perplexity: 12.1469 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2936/2936 [==============================] - 337s 115ms/step - loss: 2.0316 - accuracy: 0.4886 - perplexity: 8.0190 - val_loss: 2.3837 - val_accuracy: 0.4278 - val_perplexity: 11.5808 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2936/2936 [==============================] - 333s 114ms/step - loss: 2.0386 - accuracy: 0.4867 - perplexity: 8.0632 - val_loss: 2.3939 - val_accuracy: 0.4268 - val_perplexity: 11.7099 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2936/2936 [==============================] - 331s 113ms/step - loss: 2.0346 - accuracy: 0.4872 - perplexity: 8.0271 - val_loss: 2.3929 - val_accuracy: 0.4320 - val_perplexity: 11.6827 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 2.0752 - accuracy: 0.4750 - perplexity: 8.2709 - val_loss: 2.2333 - val_accuracy: 0.4550 - val_perplexity: 9.9208 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 2.0099 - accuracy: 0.4875 - perplexity: 7.7175 - val_loss: 2.2053 - val_accuracy: 0.4639 - val_perplexity: 9.7113 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9782 - accuracy: 0.4940 - perplexity: 7.4629 - val_loss: 2.2219 - val_accuracy: 0.4588 - val_perplexity: 9.8068 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9527 - accuracy: 0.4993 - perplexity: 7.2663 - val_loss: 2.2132 - val_accuracy: 0.4616 - val_perplexity: 9.7681 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9496 - accuracy: 0.4984 - perplexity: 7.2252 - val_loss: 2.1881 - val_accuracy: 0.4662 - val_perplexity: 9.5086 - lr: 1.0000e-05\n",
      "Epoch 15/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9349 - accuracy: 0.5020 - perplexity: 7.1151 - val_loss: 2.1880 - val_accuracy: 0.4666 - val_perplexity: 9.5139 - lr: 1.0000e-05\n",
      "Epoch 16/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9284 - accuracy: 0.5036 - perplexity: 7.0667 - val_loss: 2.1921 - val_accuracy: 0.4656 - val_perplexity: 9.5717 - lr: 1.0000e-05\n",
      "Epoch 17/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9254 - accuracy: 0.5040 - perplexity: 7.0432 - val_loss: 2.1885 - val_accuracy: 0.4668 - val_perplexity: 9.5469 - lr: 1.0000e-06\n",
      "Epoch 18/50\n",
      "2936/2936 [==============================] - 327s 112ms/step - loss: 1.9238 - accuracy: 0.5044 - perplexity: 7.0315 - val_loss: 2.1881 - val_accuracy: 0.4670 - val_perplexity: 9.5387 - lr: 1.0000e-06\n",
      "Epoch 19/50\n",
      "2936/2936 [==============================] - 328s 112ms/step - loss: 1.9230 - accuracy: 0.5046 - perplexity: 7.0259 - val_loss: 2.1880 - val_accuracy: 0.4670 - val_perplexity: 9.5393 - lr: 1.0000e-07\n",
      "It took 6348.724717617035 seconds to complete the training\n"
     ]
    }
   ],
   "source": [
    "train_ds = get_tf_pipeline(train_data_seq[:50], n_seq, stride=25, batch_size=128)\n",
    "valid_ds = get_tf_pipeline(val_data_seq, n_seq, stride=n_seq, batch_size=128)\n",
    "\n",
    "os.makedirs('eval', exist_ok=True)\n",
    "\n",
    "# Logging the performance metrics to a CSV file\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join('eval','1_language_modelling.log'))\n",
    "\n",
    "monitor_metric = 'val_perplexity'\n",
    "mode = 'min' \n",
    "print(\"Using metric={} and mode={} for EarlyStopping\".format(monitor_metric, mode))\n",
    "\n",
    "# Reduce LR callback\n",
    "# This function keeps the initial learning rate for the first ten epochs\n",
    "# and decreases it exponentially after that.\n",
    "def scheduler(epoch, lr):  \n",
    "    if epoch==0:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.1\n",
    "\n",
    "#lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "\n",
    "lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=monitor_metric, factor=0.1, patience=2, mode=mode, min_lr=1e-8\n",
    ")\n",
    "\n",
    "# EarlyStopping itself increases the memory requirement\n",
    "# restore_best_weights will increase the memory req for large models\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=monitor_metric, patience=5, mode=mode, restore_best_weights=False\n",
    ")\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "model.fit(train_ds, epochs=50, \n",
    "          validation_data = valid_ds,\n",
    "          callbacks=[es_callback, lr_callback, csv_logger])\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"It took {} seconds to complete the training\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "tf.keras.models.save_model(model, os.path.join('models', '2_gram_lm.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 512)    376832      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, None, 1024), 4724736     embedding_1[0][0]                \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 512)    524800      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, None, 735)    377055      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 735)    0           final_out[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,003,423\n",
      "Trainable params: 6,003,423\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = tf.keras.layers.Input(shape=(None,))\n",
    "inp_state = tf.keras.layers.Input(shape=(1024,))\n",
    "\n",
    "emb_layer = tf.keras.layers.Embedding(input_dim=n_vocab+1, output_dim=512, input_shape=(None,))\n",
    "emb_out = emb_layer(inp)\n",
    "    # Defining an LSTM layer\n",
    "gru_layer = tf.keras.layers.GRU(1024, return_state=True, return_sequences=True)\n",
    "gru_out, gru_state = gru_layer(emb_out, initial_state=inp_state)\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(512, activation='relu')\n",
    "dense_out = dense_layer(gru_out)\n",
    "final_layer = tf.keras.layers.Dense(n_vocab, name='final_out')\n",
    "final_out = final_layer(dense_out)\n",
    "softmax_out = tf.keras.layers.Activation(activation='softmax')(final_out)\n",
    "\n",
    "infer_model = tf.keras.models.Model(inputs=[inp, inp_state], outputs=[softmax_out, gru_state])\n",
    "\n",
    "emb_layer.set_weights(model.get_layer('embedding').get_weights())\n",
    "gru_layer.set_weights(model.get_layer('gru').get_weights())\n",
    "dense_layer.set_weights(model.get_layer('dense').get_weights())\n",
    "final_layer.set_weights(model.get_layer('final_out').get_weights())\n",
    "infer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making 173 predictions from input\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunks. cornelia .\n",
      " `` i 'm going to bed , '' said-miss cornelia replied : ' i am sure young thomas says it i can not be .\n",
      " i 'm going to see you again , and i 'll tell you what it is . ''\n",
      " `` i 'm going to be a man , '' said mrs. jo , standing up and downstair 's head .\n",
      " `` i 'm going to start at once , '' said the story girls , after another , and then he sailed into the sea , and then he said : `` it 's all right , and i 'm now going to be a good many .\n",
      " it 's all right , and i 'll tells me that you will be able to die .\n",
      " i 'm sure-i thinking of the princess , '' said mrs just , as he spoke , `` it 's all right , and i 'm not going to be a good time .\n",
      " i 'm going to see you again , and i 'll tells me that you will be able to do it ... i 'm going to say that i have n't anything to do with them .\n",
      " i 'm going to say that i have n't any time to go to the house . ''\n",
      " `` i do n't know what it is , '' said the story girl , `` i 'm goin , '' said the story girl .\n",
      " `` i 'm going to be a man , '\n"
     ]
    }
   ],
   "source": [
    "text = ngrams(\n",
    "    \"CHAPTER I. Down the Rabbit-Hole Alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought Alice ` without pictures or conversation ? ' \".lower(), \n",
    "    n\n",
    ")\n",
    "\n",
    "# CHAPTER I. Down the Rabbit-Hole Alice was beginning to get very tired of sitting by her sister on the bank\n",
    "seq = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "# build up model state using the given string\n",
    "print(\"Making {} predictions from input\".format(len(seq[0])))\n",
    "\n",
    "model.reset_states()\n",
    "state = np.zeros(shape=(1,1024))\n",
    "for c in seq[0]:    \n",
    "    out, state = infer_model.predict([np.array([[c]]), state])\n",
    "\n",
    "# get final prediction after feeding the input string\n",
    "wid = int(np.argmax(out[0],axis=-1).ravel())\n",
    "word = tokenizer.index_word[wid]\n",
    "text.append(word)\n",
    "\n",
    "x = np.array([[wid]])\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "    out, state = infer_model.predict([x, state])\n",
    "    # Get the word id and the word\n",
    "    out_argsort = np.argsort(out[0], axis=-1).ravel()    \n",
    "    #i = np.random.choice(list(range(-2,0)), p=out_argsort[-2:]/out_argsort[-2:].sum())    \n",
    "    wid = int(out_argsort[-1])    \n",
    "    word = tokenizer.index_word[wid]\n",
    "    \n",
    "    if word.endswith(' '):\n",
    "        if np.random.normal()>0.5:\n",
    "            width = 3\n",
    "            i = np.random.choice(list(range(-width,0)), p=out_argsort[-width:]/out_argsort[-width:].sum())    \n",
    "            wid = int(out_argsort[i])    \n",
    "            word = tokenizer.index_word[wid]\n",
    "    # Append the prediction\n",
    "    text.append(word)\n",
    "    \n",
    "    # recursively make the current prediction the next input\n",
    "    x = np.array([[wid]])\n",
    "    \n",
    "    \n",
    "print(''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://gist.github.com/Gregorgeous/dbad1ec22efc250c76354d949a13cec3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(os.path.join('models', '2_gram_lm.h5'), compile=False)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', PerplexityMetric()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_one_step(model, input_, state):    \n",
    "    #print('a',input_,)\n",
    "    #print('b',state)\n",
    "    output, new_state = model.predict([input_, state])\n",
    "    return output, new_state\n",
    "\n",
    "def beam_search(model, input_, state, beam_depth=5, beam_width=3):\n",
    "    \n",
    "    def recursive_fn(input_, state, sequence, prob, i):\n",
    "        output, state = beam_one_step(model, input_, state)\n",
    "        top_probs, top_ids = tf.nn.top_k(output, k=beam_width)\n",
    "        top_probs, top_ids = top_probs.numpy().ravel(), top_ids.numpy().ravel()\n",
    "        #print(top_probs, top_ids)\n",
    "        while i < beam_depth:\n",
    "            i += 1\n",
    "            for p, wid in zip(top_probs, top_ids):\n",
    "                prob *= p\n",
    "                #print(wid)\n",
    "                sequence.append(wid)\n",
    "                sequence, prob, state = recursive_fn(np.array([[wid]]), state, sequence, prob, i)\n",
    "                #print(sequence)\n",
    "                if len(sequence)==beam_depth:\n",
    "                    results.append((list(sequence), state, prob))\n",
    "                    \n",
    "                sequence.pop()\n",
    "                \n",
    "        return sequence, prob, state\n",
    "    \n",
    "    results = []\n",
    "    sequence = []\n",
    "    prob = 1.0\n",
    "    recursive_fn(input_, state, sequence, prob, 0)    \n",
    "    results = sorted(results, key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making 173 predictions from input\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tol\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who w\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the be\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of the\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , anne\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous \n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it want\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , an\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , and\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as \n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      "\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and the\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther was\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an o\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worl\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradi\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anne\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compan\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys ...\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys .... , who ha\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys .... , who has had a go\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys .... , who has had a goness of th\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys .... , who has had a goness of them ? ''\n",
      " `\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys .... , who has had a goness of them ? ''\n",
      " `` i 'm goi\n",
      "chapter i. down the rabbit-hole alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought alice ` without pictures or conversation ? ' unkunk. h. tolor , who were the bells of theard , annever thous .\n",
      " it wantially , ancing , andon was as of them .\n",
      " they were , and thearther wasted , an of the worly contradious , anneties , andons , them 's compant boys .... , who has had a goness of them ? ''\n",
      " `` i 'm goisomed , ''\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-acf72b90614e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mbest_beam_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_beam_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(model, input_, state, beam_depth, beam_width)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mrecursive_fn\u001b[0;34m(input_, state, sequence, prob, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#print(wid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbeam_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mrecursive_fn\u001b[0;34m(input_, state, sequence, prob, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#print(wid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbeam_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mrecursive_fn\u001b[0;34m(input_, state, sequence, prob, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#print(wid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbeam_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mrecursive_fn\u001b[0;34m(input_, state, sequence, prob, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#print(wid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbeam_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mrecursive_fn\u001b[0;34m(input_, state, sequence, prob, i)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m#print(wid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print(sequence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbeam_depth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mrecursive_fn\u001b[0;34m(input_, state, sequence, prob, i)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecursive_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtop_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeam_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtop_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-77b1d186b395>\u001b[0m in \u001b[0;36mbeam_one_step\u001b[0;34m(model, input_, state)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print('a',input_,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print('b',state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \"\"\"\n\u001b[0;32m-> 1652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m   def interleave(self,\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   4069\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4070\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 4071\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   4072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4073\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[1;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2532\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2534\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mkwarg_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     func_args = _get_defun_inputs_from_args(\n\u001b[0;32m--> 898\u001b[0;31m         args, arg_names, flat_shapes=arg_shapes)\n\u001b[0m\u001b[1;32m    899\u001b[0m     func_kwargs = _get_defun_inputs_from_kwargs(\n\u001b[1;32m    900\u001b[0m         kwargs, flat_shapes=kwarg_shapes)\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs_from_args\u001b[0;34m(args, names, flat_shapes)\u001b[0m\n\u001b[1;32m   1130\u001b[0m   \u001b[0;34m\"\"\"Maps Python function positional args to graph-construction inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m   return _get_defun_inputs(\n\u001b[0;32m-> 1132\u001b[0;31m       args, names, structure=args, flat_shapes=flat_shapes)\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs\u001b[0;34m(args, names, structure, flat_shapes)\u001b[0m\n\u001b[1;32m   1210\u001b[0m           placeholder = graph_placeholder(\n\u001b[1;32m   1211\u001b[0m               \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m               name=requested_name)\n\u001b[0m\u001b[1;32m   1213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m           \u001b[0;31m# Sometimes parameter names are not valid op names, so fall back to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     39\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m       attrs=attrs, name=name)\n\u001b[0m\u001b[1;32m     41\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1817\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1645\u001b[0m   \u001b[0;31m# Add attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[0;31m# It might be worth creating a convenient way to re-use the same status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = ngrams(\n",
    "    \"CHAPTER I. Down the Rabbit-Hole Alice was beginning to get very tired of sitting by her sister on the bank  , and of having nothing to do : once or twice she had peeped into the book her sister was reading , but it had no pictures or conversations in it , ` and what is the use of a book , ' thought Alice ` without pictures or conversation ? ' \".lower(), \n",
    "    n\n",
    ")\n",
    "\n",
    "# CHAPTER I. Down the Rabbit-Hole Alice was beginning to get very tired of sitting by her sister on the bank\n",
    "seq = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "# build up model state using the given string\n",
    "print(\"Making {} predictions from input\".format(len(seq[0])))\n",
    "\n",
    "model.reset_states()\n",
    "state = np.zeros(shape=(1,1024))\n",
    "for c in seq[0]:    \n",
    "    out, state = infer_model.predict([np.array([[c]]), state])\n",
    "\n",
    "# get final prediction after feeding the input string\n",
    "wid = int(np.argmax(out[0],axis=-1).ravel())\n",
    "word = tokenizer.index_word[wid]\n",
    "text.append(word)\n",
    "\n",
    "x = np.array([[wid]])\n",
    "\n",
    "prev_beam = None\n",
    "for i in range(100):    \n",
    "    result = beam_search(infer_model, x, state, 5, 3)\n",
    "    best_beam_ids, state, _  = result[0]    \n",
    "    x = np.array([[best_beam_ids[-1]]])\n",
    "    \n",
    "    if tokenizer.index_word[best_beam_ids[-1]].endswith(' '):    \n",
    "        # to reduce importance of high prob ones\n",
    "        # if the same sequence is repeating we'll avoid it explicitly\n",
    "        if prev_beam != best_beam_ids:\n",
    "            n_probs = np.array([p for _,_,p in result[:5]])\n",
    "            p_j = np.random.choice(list(range(5)), p=n_probs/n_probs.sum())        \n",
    "        else:\n",
    "            n_probs = np.array([p for _,_,p in result[1:6]])\n",
    "            p_j = np.random.choice(list(range(1,6)), p=n_probs/n_probs.sum())        \n",
    "            \n",
    "        best_beam_ids, state, _ = result[p_j]\n",
    "        x = np.array([[best_beam_ids[-1]]])\n",
    "    \n",
    "    prev_beam=best_beam_ids\n",
    "    text.extend([tokenizer.index_word[w] for w in best_beam_ids])\n",
    "    print(''.join(text))\n",
    "\n",
    "print('\\n')\n",
    "print('='*60)\n",
    "print(\"Final text: \")\n",
    "print(''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 2, 4]\n",
      "[1, 2, 5]\n",
      "[1, 2]\n",
      "[1, 3, 4]\n",
      "[1, 3, 5]\n",
      "[1, 3, 6]\n",
      "[1, 3]\n",
      "[1, 4, 5]\n",
      "[1, 4, 6]\n",
      "[1, 4, 7]\n",
      "[1, 4]\n",
      "[1, 2]\n",
      "[1, 3]\n",
      "[1, 4]\n",
      "[1]\n",
      "[[1, 2, 3], [1, 2, 4], [1, 2, 5], [1, 2], [1, 3, 4], [1, 3, 5], [1, 3, 6], [1, 3], [1, 4, 5], [1, 4, 6], [1, 4, 7], [1, 4], [1, 2], [1, 3], [1, 4]]\n"
     ]
    }
   ],
   "source": [
    "outer_seq = []\n",
    "def f1(a, seq, j):\n",
    "    seq.append(a)\n",
    "    while j<2:\n",
    "        j += 1\n",
    "        for i in range(3):            \n",
    "            seq = f1(a+i+1, seq, j)\n",
    "            print(seq)\n",
    "            outer_seq.append(list(seq))\n",
    "            seq.pop()\n",
    "            \n",
    "    return seq\n",
    "\n",
    "print(f1(1,[],0))\n",
    "print(outer_seq)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print([1,2]==[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]], shape=(2, 2), dtype=int64)\n",
      "tf.Tensor([1 1], shape=(2,), dtype=int64)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-b21f6e151959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print(res[0][i].indices)\n",
    "    print(res[0][i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.8381094]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.exp(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import gen_ctc_ops\n",
    "gen_ctc_ops??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.raw_ops import CTCBeamSearchDecoder\n",
    "CTCBeamSearchDecoder??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 2]], shape=(3, 2), dtype=int64)\n",
      "tf.Tensor([1 0 1], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "res = tf.nn.ctc_greedy_decoder(\n",
    "        tf.transpose(logits,[1,0,2]), [logits.shape[1]], merge_repeated=True\n",
    "    )\n",
    "i=0\n",
    "print(res[0][i].indices)\n",
    "\n",
    "print(res[0][i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
