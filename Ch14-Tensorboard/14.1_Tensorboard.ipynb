{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring models (Tensorboard)\n",
    "\n",
    "Montiroing models is crucial part when training a model. Continuous monitoring of the model enables to ensure the model training is functioning as intended. Furthermore, it can also provide insights to improvements that can be made to improve model performance and execution time. Here, we will see how we can use the TensorBoard to continuously monitor the model, profile the model as well as visualize various data types such as images and text.\n",
    "\n",
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/manning_tf2_in_action/blob/master/Ch09/13.1_Tensorboard.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important check before running the Tensorboard\n",
    "\n",
    "In order to make sure all the features of the Tensorboard work, make sure to instell the `libcupti` library. It stands for **Lib**rary - **CU**DA **P**rofiling **T**ools **I**nterface. It is a GPU profiling toolkit by NVIDIA, which is required by the Tensboard profiling dashboard.\n",
    "\n",
    "## Linux Installation\n",
    "On linux you can install this using `sudo apt-get install libcupti-dev`.\n",
    "\n",
    "## Windows Installation\n",
    "\n",
    "As opposed to the Linux installation, Windows installation require more work.\n",
    "\n",
    "* Make sure you have installed the required CUDA installation (e.g. CUDA 11 [>= TensorFlow 2.4.0])\n",
    "* Next, open the NVIDIA Control Panel to do several changes (These were suggested in the following [Github issue](https://github.com/tensorflow/tensorflow/issues/35860#issuecomment-603728531)),\n",
    "  * Make sure you have set the Developer Mode by clicking Desktop > Set Developer Mode\n",
    "  * Make sure you have enabled GRU profiling to all users and not just the adiministrator. \n",
    "* For more errors you might face, refer the following page from the official [NVIDIA website](https://developer.nvidia.com/nvidia-development-tools-solutions-err-nvgpuctrperm-cupti)\n",
    "* To install `libcupti` (Motivated by this [Stackoverflow question](https://stackoverflow.com/questions/54028188/how-to-install-cuda-profiling-tools-interface-on-windows-10/54029753)),\n",
    "  * Copy `libcupti_<version>.dll`, `nvperf_host.dll` and `nvperf_target.dll` from the `extras\\CUPTI\\lib64` to the `bin` folder. Make sure the `libcupti` file has the name, `libcupti_110.dll`.\n",
    "  * Copy all files in the `extras\\CUPTI\\lib64` to `lib\\x64`\n",
    "  * Copy all files in the `extras\\CUPTI\\include` to `include`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: random module is not imported. Setting the seed for random failed.\n",
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import shutil\n",
    "import os\n",
    "%load_ext tensorboard\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except:\n",
    "        print(\"Couldn't set memory_growth\")\n",
    "        pass\n",
    "    \n",
    "def fix_random_seed(seed):\n",
    "    \"\"\" Setting the random seed of various libraries \"\"\"\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "random_seed=4321\n",
    "fix_random_seed(random_seed)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Image Data on the TensorBoard\n",
    "\n",
    "## Importing the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': <PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>, 'train': <PrefetchDataset shapes: {image: (28, 28, 1), label: ()}, types: {image: tf.uint8, label: tf.int64}>}\n"
     ]
    }
   ],
   "source": [
    "# Construct a tf.data.Dataset\n",
    "fashion_ds = tfds.load('fashion_mnist')\n",
    "\n",
    "print(fashion_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training/validation/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_test_datasets(fashion_ds, batch_size, flatten_images=False):\n",
    "    \n",
    "    # Get the training dataset, shuffle it, and output a tuple of (image, label) \n",
    "    train_ds = fashion_ds[\"train\"].shuffle(batch_size*20).map(lambda xy: (xy[\"image\"], tf.reshape(xy[\"label\"], [-1])))\n",
    "    # Get the testing dataset, and output a tuple of (image, label)\n",
    "    test_ds = fashion_ds[\"test\"].map(lambda xy: (xy[\"image\"], tf.reshape(xy[\"label\"], [-1])))\n",
    "    \n",
    "    if flatten_images:\n",
    "        # Flatten the images to a 1D vector for fully-connected networks\n",
    "        train_ds = train_ds.map(lambda x,y: (tf.reshape(x, [-1]), y))\n",
    "        test_ds = test_ds.map(lambda x,y: (tf.reshape(x, [-1]), y))\n",
    "    \n",
    "    # Make the validation dataset the first 10000 data\n",
    "    valid_ds = train_ds.take(10000).batch(batch_size)\n",
    "    # Make training dataset the rest\n",
    "    train_ds = train_ds.skip(10000).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `tf.summary` to visualize images on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to the tensorboard\n",
      "\tDone\n"
     ]
    }
   ],
   "source": [
    "# Defining the ID to Label map\n",
    "id2label_map = {\n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2:\"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\"\n",
    "}\n",
    "\n",
    "print(\"Writing to the tensorboard\")\n",
    "\n",
    "image_logdir = \"./logs/data/train\"\n",
    "\n",
    "# Remove the directory if already exists\n",
    "if os.path.exists(image_logdir):\n",
    "    shutil.rmtree(image_logdir)\n",
    "\n",
    "# Define a summary writer\n",
    "image_writer = tf.summary.create_file_writer(image_logdir)\n",
    "\n",
    "# Write an image with its category\n",
    "with image_writer.as_default():\n",
    "    for data in fashion_ds[\"train\"].batch(1).take(10):\n",
    "        tf.summary.image(id2label_map[int(data[\"label\"].numpy())], data[\"image\"], max_outputs=20, step=0)\n",
    "\n",
    "# Write a batch of images at once\n",
    "with image_writer.as_default():\n",
    "    for data in fashion_ds[\"train\"].batch(20).take(1):\n",
    "        pass\n",
    "    tf.summary.image(\"A training data batch\", data[\"image\"], max_outputs=20, step=0)\n",
    "\n",
    "print('\\tDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spinning up the TensorBoard\n",
    " \n",
    "Here we're using tensorboard magic command on jupyter notebook. This gives us the same board inline, as if you were to open the Tensorboard in a browser tab. If you call the same command multiple times with the same `logdir` it will reuse the same Tensorboard. If the directories are different a new TensorBoard is spun up. \n",
    "\n",
    "**Note**: On windows, it's not just enough to kill the process to restart the tensorboard. You have to delete the `AppData\\Local\\Temp\\.tensorboard-info` directory as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: taskkill: command not found\n",
      "rmdir: failed to remove '/s': No such file or directory\n",
      "rmdir: failed to remove '/q': No such file or directory\n",
      "rmdir: failed to remove 'C:UsersthushAppDataLocalTemp.tensorboard-info': No such file or directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b3d82bc14440d921\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b3d82bc14440d921\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!taskkill /IM \"tensorboard.exe\" /F\n",
    "!rmdir /s /q C:\\Users\\thush\\AppData\\Local\\Temp\\.tensorboard-info\n",
    "%tensorboard --logdir ./logs --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Open [Tensorboard](http://localhost:6006) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking models on TensorBoard\n",
    "\n",
    "Here we will compare two models; a fully-connected model and a convolutional neural network. To compare them we will use the Fashion-MNIST dataset.\n",
    "\n",
    "## Monitoring the performance of the fully-connected network\n",
    "\n",
    "Here we analyse the training and validation performance of the fully-connected network. We will track loss and accuracy of the model.\n",
    "\n",
    "### Fully-connected network\n",
    "\n",
    "Here we define a fully connected network with 3 layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "dense_model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 9s 10ms/step - loss: 11.6269 - accuracy: 0.7160 - val_loss: 0.8061 - val_accuracy: 0.8049\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.6295 - accuracy: 0.8142 - val_loss: 0.5708 - val_accuracy: 0.8158\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 7s 9ms/step - loss: 0.4914 - accuracy: 0.8354 - val_loss: 0.4550 - val_accuracy: 0.8500\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.4478 - accuracy: 0.8424 - val_loss: 0.5228 - val_accuracy: 0.8285\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.4090 - accuracy: 0.8554 - val_loss: 0.4636 - val_accuracy: 0.8466\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.4087 - accuracy: 0.8563 - val_loss: 0.4146 - val_accuracy: 0.8603\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3832 - accuracy: 0.8642 - val_loss: 0.4126 - val_accuracy: 0.8608\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3671 - accuracy: 0.8684 - val_loss: 0.4426 - val_accuracy: 0.8531\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3706 - accuracy: 0.8657 - val_loss: 0.4479 - val_accuracy: 0.8553\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 7s 8ms/step - loss: 0.3525 - accuracy: 0.8735 - val_loss: 0.4091 - val_accuracy: 0.8555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ab220cb588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_log_dir = \"./logs/dense\"\n",
    "\n",
    "if os.path.exists(dense_log_dir):\n",
    "    shutil.rmtree(dense_log_dir)\n",
    "\n",
    "batch_size = 64\n",
    "tr_ds, v_ds, ts_ds = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=True)\n",
    "\n",
    "# Defining the tensorboard callback, it will log information to the defined log_dir directory\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=dense_log_dir, profile_batch=0)\n",
    "\n",
    "# Train the model\n",
    "dense_model.fit(tr_ds, validation_data=v_ds, epochs=10, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If TensorBoard is not running, run the following command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring the performance of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        4624      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                31370     \n",
      "=================================================================\n",
      "Total params: 36,826\n",
      "Trainable params: 36,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "conv_model = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(5,5), strides=(2,2), padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_log_dir = \"./logs/conv\"\n",
    "\n",
    "if os.path.exists(conv_log_dir):\n",
    "    shutil.rmtree(conv_log_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 2.0809 - accuracy: 0.7383 - val_loss: 0.3872 - val_accuracy: 0.8623\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.3631 - accuracy: 0.8694 - val_loss: 0.3757 - val_accuracy: 0.8668\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.3259 - accuracy: 0.8819 - val_loss: 0.3696 - val_accuracy: 0.8793\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.2963 - accuracy: 0.8910 - val_loss: 0.3702 - val_accuracy: 0.8753\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.2850 - accuracy: 0.8969 - val_loss: 0.3676 - val_accuracy: 0.8825\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.2704 - accuracy: 0.9003 - val_loss: 0.3966 - val_accuracy: 0.8725\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 0.2601 - accuracy: 0.9044 - val_loss: 0.3620 - val_accuracy: 0.8828\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 16s 20ms/step - loss: 0.2548 - accuracy: 0.9047 - val_loss: 0.3771 - val_accuracy: 0.8814\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.2380 - accuracy: 0.9123 - val_loss: 0.4256 - val_accuracy: 0.8741\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 19s 24ms/step - loss: 0.2357 - accuracy: 0.9128 - val_loss: 0.4214 - val_accuracy: 0.8797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ab1f3e11d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "tr_ds, v_ds, ts_ds = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=False)\n",
    "\n",
    "# This tensorboard call back does the followin\n",
    "# 1. Log loss and accuracy\n",
    "# 2. Plot activation histograms every two epochs\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=conv_log_dir, histogram_freq=2, profile_batch=0)\n",
    "\n",
    "conv_model.fit(tr_ds, validation_data=v_ds, epochs=10, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Open [Tensorboard](http://localhost:6006) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard with custom training loops\n",
    "\n",
    "Here we train two models with and without batch normalization. Then we will analyze the mean and standard deviation of the absolute weights of the second layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "dense_model = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),    \n",
    "    layers.Dense(256, activation='relu', name='log_layer'),    \n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "dense_model_bn = models.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu', name='log_layer_bn'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dense_model_bn.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_log_dir = \"./logs/weights_exp\"\n",
    "\n",
    "if os.path.exists(exp_log_dir):\n",
    "    shutil.rmtree(exp_log_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "\tDone\n",
      "Training epoch 2\n",
      "\tDone\n",
      "Training epoch 3\n",
      "\tDone\n",
      "Training epoch 4\n",
      "\tDone\n",
      "Training epoch 5\n",
      "\tDone\n",
      "Training completed\n",
      "\n",
      "Training epoch 1\n",
      "\tDone\n",
      "Training epoch 2\n",
      "\tDone\n",
      "Training epoch 3\n",
      "\tDone\n",
      "Training epoch 4\n",
      "\tDone\n",
      "Training epoch 5\n",
      "\tDone\n",
      "Training completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataset, log_dir, log_layer_name, epochs):    \n",
    "    \n",
    "    # Define the writer\n",
    "    writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    step = 0\n",
    "    # Open the writer\n",
    "    with writer.as_default():        \n",
    "        tot_iterations_in_epoch = 0  # Total iterations in an epoch\n",
    "        \n",
    "        # For every epoch\n",
    "        for e in range(epochs):\n",
    "            print(\"Training epoch {}\".format(e+1))\n",
    "            # For every iteration in the epoch\n",
    "            for batch in tr_ds:\n",
    "                # Compute the step\n",
    "                \n",
    "                # Train with one batch\n",
    "                model.train_on_batch(*batch)\n",
    "                # Get the weights of the layer [0] - weights / [1] - bias\n",
    "                w = model.get_layer(log_layer_name).get_weights()[0]\n",
    "                \n",
    "                # Log mean and std of absolute weights\n",
    "                tf.summary.scalar(\"mean_weights\", np.mean(np.abs(w)), step=step)\n",
    "                tf.summary.scalar(\"std_weights\", np.std(np.abs(w)), step=step)\n",
    "                \n",
    "                # Flush to the disk from the buffer\n",
    "                writer.flush()\n",
    "                \n",
    "                step += 1\n",
    "            print('\\tDone')\n",
    "    \n",
    "    print(\"Training completed\\n\")\n",
    "    \n",
    "batch_size = 64\n",
    "tr_ds, _, _ = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=True)\n",
    "train_model(dense_model, tr_ds, exp_log_dir + '/standard', \"log_layer\", 5)\n",
    "\n",
    "tr_ds, _, _ = get_train_valid_test_datasets(fashion_ds, batch_size=batch_size, flatten_images=True)\n",
    "train_model(dense_model_bn, tr_ds, exp_log_dir + '/bn', \"log_layer_bn\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling models to detect performance bottlenecks\n",
    "\n",
    "Here we will profile our convolutional neural network to undrestand performance bottlenecks and computational intensive parts of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the data\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Retrieve the data\n",
    "if not os.path.exists(os.path.join('data', '17flowers.tgz')):\n",
    "    \n",
    "    url=\"https://www.robots.ox.ac.uk/~vgg/data/flowers/17/17flowers.tgz\"\n",
    "\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "\n",
    "    # Write to a file\n",
    "    with open(os.path.join('data', '17flowers.tgz'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "else:\n",
    "    print(\"The tar file already exists.\")\n",
    "\n",
    "if not os.path.exists(os.path.join('data', '17flowers')):\n",
    "    # Write to a file\n",
    "    tarf = tarfile.open(os.path.join(\"data\",\"17flowers.tgz\"))\n",
    "    tarf.extractall(os.path.join('data', '17flowers'))\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model():\n",
    "    \n",
    "    conv_model = models.Sequential([\n",
    "        layers.Conv2D(filters=64, kernel_size=(5,5), strides=(1,1), padding='same', activation='relu', input_shape=(64,64,3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
    "        layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=512, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "        layers.Flatten(),        \n",
    "        layers.Dense(512),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.LayerNormalization(),                \n",
    "        layers.Dense(256),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.LayerNormalization(),                \n",
    "        layers.Dense(17),\n",
    "        layers.Activation('softmax', dtype='float32')\n",
    "    ])\n",
    "    return conv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"TF_GPU_THREAD_MODE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 7s 106ms/step - loss: 3.3394 - accuracy: 0.2784 - val_loss: 3.3961 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 4s 81ms/step - loss: 2.2042 - accuracy: 0.3495 - val_loss: 3.2204 - val_accuracy: 0.0280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36ef6abe48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "profile_log_dir = \"./logs/profile\"\n",
    "\n",
    "if os.path.exists(profile_log_dir):\n",
    "    shutil.rmtree(profile_log_dir)\n",
    "    \n",
    "conv_model = get_cnn_model()\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "#conv_model.summary()\n",
    "\n",
    "def get_flower_datasets(image_dir, batch_size, flatten_images=False):\n",
    "\n",
    "    # Get the training dataset, shuffle it, and output a tuple of (image, label)\n",
    "    dataset = tf.data.Dataset.list_files(os.path.join(image_dir,'*.jpg'), shuffle=False)\n",
    "\n",
    "    def get_image_and_label(file_path):\n",
    "\n",
    "        tokens = tf.strings.split(file_path, os.path.sep)        \n",
    "        label = (tf.strings.to_number(tf.strings.split(tf.strings.split(tokens[-1],'.')[0], '_')[-1])-1)//80\n",
    "\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "        return tf.image.resize(img, [64, 64]), label\n",
    "\n",
    "    dataset = dataset.map(get_image_and_label).shuffle(400)\n",
    "\n",
    "    # Make the validation dataset the first 10000 data\n",
    "    valid_ds = dataset.take(250).batch(batch_size)\n",
    "    # Make training dataset the rest\n",
    "    train_ds = dataset.skip(250).batch(batch_size)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "batch_size = 32\n",
    "tr_ds, v_ds = get_flower_datasets(\n",
    "    os.path.join('data', '17flowers','jpg'), batch_size=batch_size, flatten_images=False\n",
    ")\n",
    "    \n",
    "# This tensorboard call back does the followin\n",
    "# 1. Log loss and accuracy\n",
    "# 2. Profile the model memory/time for 10 batches\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=profile_log_dir, profile_batch=[10, 20])\n",
    "\n",
    "conv_model.fit(tr_ds, validation_data=v_ds, epochs=2, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the CNN backed up by TensorBoard profiler findings\n",
    "\n",
    "We are going to introduce the following changes\n",
    "* Optimize the `tf.data` pipeline by incorporating prefetching and parallaized map functions\n",
    "* Use mixed precision training\n",
    "* Use private threads for the GPU to launch kernels\n",
    "\n",
    "GPUs having a CUDA computing capability of more than 7 will be able to run mixed precision computations. If not, you will see an error similar to below.\n",
    "\n",
    "```\n",
    "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
    "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
    "  GeForce GTX 960M, compute capability 5.0\n",
    "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
    "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
    "```\n",
    "\n",
    "If you have the capability, you will see something like,\n",
    "\n",
    "```\n",
    "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
    "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070, compute capability 7.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Environment Variables\n",
    "\n",
    "To set environment variables you can do the following.\n",
    "\n",
    "### Linux\n",
    "\n",
    "Set the environment variable by,\n",
    "* Opening a terminal \n",
    "* Run `export TF_GPU_THREAD_MODE=gpu_private`\n",
    "* Verify the environment variable is set by calling `echo $TF_GPU_THREAD_MODE`\n",
    "* Open a new shell and start the jupyter notebook server\n",
    "\n",
    "### Windows\n",
    "\n",
    "Set the environment variable by,\n",
    "* From the start menu select `Edit the system environment variables`\n",
    "* Click the button called `environment variables`\n",
    "* Add a new environment variable `TF_GPU_THREAD_MODE=gpu_private` in the opened dialog\n",
    "* Open a new command prompt and start the jupyter notebook server\n",
    "\n",
    "### Conda environment\n",
    "\n",
    "To set environment variables in a conda environment,\n",
    "* Activate the conda environment with `conda activate manning.tf2`\n",
    "* Run `conda env config vars set TF_GPU_THREAD_MODE=gpu_private`\n",
    "* Deactivate and reactivate the environment, for the variable to take effect\n",
    "* Start the jupyter notebook server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_profile_log_dir = \"./logs/optimized_profile_wo_gpu_private\"\n",
    "#opt_profile_log_dir = \"./logs/optimized_profile\"\n",
    "\n",
    "if os.path.exists(opt_profile_log_dir):\n",
    "    shutil.rmtree(opt_profile_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070, compute capability 7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce RTX 2070, compute capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "35/35 [==============================] - 12s 167ms/step - loss: 3.5535 - accuracy: 0.2541 - val_loss: 3.8611 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "35/35 [==============================] - 4s 88ms/step - loss: 2.1774 - accuracy: 0.3194 - val_loss: 3.3964 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "conv_model = get_cnn_model()\n",
    "\n",
    "conv_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def get_flower_datasets(image_dir, batch_size, flatten_images=False):\n",
    "\n",
    "    # Get the training dataset, shuffle it, and output a tuple of (image, label)\n",
    "    dataset = tf.data.Dataset.list_files(os.path.join(image_dir,'*.jpg'), shuffle=False)\n",
    "\n",
    "    def get_image_and_label(file_path):\n",
    "\n",
    "        tokens = tf.strings.split(file_path, os.path.sep)        \n",
    "        label = (tf.strings.to_number(tf.strings.split(tf.strings.split(tokens[-1],'.')[0], '_')[-1])-1)//80\n",
    "\n",
    "        # load the raw data from the file as a string\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "\n",
    "        return tf.image.resize(img, [64, 64]), label\n",
    "\n",
    "    dataset = dataset.map(\n",
    "        get_image_and_label,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).shuffle(400)\n",
    "\n",
    "    # Make the validation dataset the first 10000 data\n",
    "    valid_ds = dataset.take(250).batch(batch_size)\n",
    "    # Make training dataset the rest\n",
    "    train_ds = dataset.skip(250).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "batch_size = 32\n",
    "tr_ds, v_ds = get_flower_datasets(os.path.join('data', '17flowers','jpg'), batch_size=batch_size, flatten_images=False)\n",
    "\n",
    "# This tensorboard call back does the followin\n",
    "# 1. Log loss and accuracy\n",
    "# 2. Profile the model memory/time for 370-410 batches\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=opt_profile_log_dir, profile_batch=[10, 20])\n",
    "\n",
    "conv_model.fit(tr_ds, validation_data=v_ds, epochs=2, callbacks=[tb_callback])\n",
    "\n",
    "# Resetting to float32\n",
    "policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_global_policy(policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the data types come into play during mixed precision training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input to the layers have the data type: <dtype: 'float16'>\n",
      "Variables in the layers have the data type: <dtype: 'float32'>\n",
      "Output of the layers have the data type: <dtype: 'float16'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Input to the layers have the data type: {}\".format(conv_model.get_layer(\"conv2d_1\").input.dtype))\n",
    "print(\"Variables in the layers have the data type: {}\".format(conv_model.get_layer(\"conv2d_1\").trainable_variables[0].dtype))\n",
    "print(\"Output of the layers have the data type: {}\".format(conv_model.get_layer(\"conv2d_1\").output.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing word vectors on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The zip file already exists.\n",
      "The extracted data already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists(os.path.join('data','glove.6B.zip')):\n",
    "    \n",
    "    print(\"Downloading\")\n",
    "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    # Get the file from web\n",
    "    r = requests.get(url)\n",
    "\n",
    "    if not os.path.exists('data'):\n",
    "        os.mkdir('data')\n",
    "    \n",
    "    # Write to a file\n",
    "    with open(os.path.join('data','glove.6B.zip'), 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    print(\"\\tDone\")\n",
    "    \n",
    "else:\n",
    "    print(\"The zip file already exists.\")\n",
    "    \n",
    "if not os.path.exists(os.path.join('data', 'glove.6B.50d.txt')):\n",
    "    print(\"Extracting data\")\n",
    "    with zipfile.ZipFile(os.path.join('data','glove.6B.zip'), 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')\n",
    "    print(\"\\tDone\")\n",
    "else:\n",
    "    print(\"The extracted data already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the most common words in the IMDB movie review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "review_ds = tfds.load('imdb_reviews')\n",
    "train_review_ds = review_ds[\"train\"]\n",
    "\n",
    "corpus = []\n",
    "for data in train_review_ds:      \n",
    "    txt = str(np.char.decode(data[\"text\"].numpy(), encoding='utf-8')).lower()\n",
    "    corpus.append(str(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 322198), ('a', 159953), ('and', 158572), ('of', 144462), ('to', 133967), ('is', 104171), ('in', 90527), ('i', 70480), ('this', 69714), ('that', 66292), ('it', 65505), ('/><br', 50935), ('was', 47024), ('as', 45102), ('for', 42843), ('with', 42729), ('but', 39764), ('on', 31619), ('movie', 30887), ('his', 29059), ('are', 28743), ('not', 28597), ('film', 27777), ('you', 27564), ('have', 27344), ('he', 26177), ('be', 25691), ('at', 22731), ('one', 22480), ('by', 21976), ('an', 21240), ('they', 20624), ('from', 19934), ('all', 19740), ('who', 19407), ('like', 18779), ('so', 18099), ('just', 17309), ('or', 16769), ('has', 16570), ('her', 16540), ('about', 16486), (\"it's\", 15970), ('some', 15280), ('if', 15189), ('out', 14510), ('what', 14055), ('very', 13633), ('when', 13609), ('more', 13170), ('there', 13094), ('she', 12234), ('would', 12027), ('even', 12010), ('good', 11926), ('my', 11766), ('only', 11566), ('their', 11317), ('no', 11273), ('really', 11065), ('had', 11042), ('which', 10898), ('can', 10797), ('up', 10776), ('were', 10528), ('see', 10410), ('than', 9807), ('we', 9417), ('-', 9355), ('been', 9074), ('into', 8990), ('get', 8959), ('will', 8926), ('story', 8743), ('much', 8739), ('because', 8736), ('most', 8477), ('how', 8456), ('other', 8229), ('also', 8007), ('first', 7985), ('its', 7963), ('time', 7945), ('do', 7904), (\"don't\", 7879), ('me', 7722), ('great', 7714), ('people', 7676), ('could', 7594), ('make', 7590), ('any', 7507), ('/>the', 7409), ('after', 7118), ('made', 7041), ('then', 6945), ('bad', 6816), ('think', 6773), ('being', 6390), ('many', 6388), ('him', 6385)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "corpus = \" \".join(corpus)\n",
    "\n",
    "cnt = Counter(corpus.split())\n",
    "print(cnt.most_common(100))\n",
    "\n",
    "most_common_words = [w for w,_ in cnt.most_common(5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read GloVe vectors and filter the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thushv89/anaconda3/envs/manning.tf2/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "Skipping line 9: field larger than field limit (131072)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.249680</td>\n",
       "      <td>-0.41242</td>\n",
       "      <td>0.12170</td>\n",
       "      <td>0.34527</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>-0.49688</td>\n",
       "      <td>-0.17862</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.656600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298710</td>\n",
       "      <td>-0.157490</td>\n",
       "      <td>-0.347580</td>\n",
       "      <td>-0.045637</td>\n",
       "      <td>-0.44251</td>\n",
       "      <td>0.187850</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>-0.184110</td>\n",
       "      <td>-0.115140</td>\n",
       "      <td>-0.78581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.236820</td>\n",
       "      <td>-0.16899</td>\n",
       "      <td>0.40951</td>\n",
       "      <td>0.63812</td>\n",
       "      <td>0.477090</td>\n",
       "      <td>-0.42852</td>\n",
       "      <td>-0.55641</td>\n",
       "      <td>-0.36400</td>\n",
       "      <td>-0.239380</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080262</td>\n",
       "      <td>0.630030</td>\n",
       "      <td>0.321110</td>\n",
       "      <td>-0.467650</td>\n",
       "      <td>0.22786</td>\n",
       "      <td>0.360340</td>\n",
       "      <td>-0.378180</td>\n",
       "      <td>-0.566570</td>\n",
       "      <td>0.044691</td>\n",
       "      <td>0.30392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.151640</td>\n",
       "      <td>0.301770</td>\n",
       "      <td>-0.16763</td>\n",
       "      <td>0.17684</td>\n",
       "      <td>0.31719</td>\n",
       "      <td>0.339730</td>\n",
       "      <td>-0.43478</td>\n",
       "      <td>-0.31086</td>\n",
       "      <td>-0.44999</td>\n",
       "      <td>-0.294860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.068987</td>\n",
       "      <td>0.087939</td>\n",
       "      <td>-0.102850</td>\n",
       "      <td>-0.13931</td>\n",
       "      <td>0.223140</td>\n",
       "      <td>-0.080803</td>\n",
       "      <td>-0.356520</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>0.10216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.708530</td>\n",
       "      <td>0.570880</td>\n",
       "      <td>-0.47160</td>\n",
       "      <td>0.18048</td>\n",
       "      <td>0.54449</td>\n",
       "      <td>0.726030</td>\n",
       "      <td>0.18157</td>\n",
       "      <td>-0.52393</td>\n",
       "      <td>0.10381</td>\n",
       "      <td>-0.175660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.347270</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>0.075693</td>\n",
       "      <td>-0.062178</td>\n",
       "      <td>-0.38988</td>\n",
       "      <td>0.229020</td>\n",
       "      <td>-0.216170</td>\n",
       "      <td>-0.225620</td>\n",
       "      <td>-0.093918</td>\n",
       "      <td>-0.80375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.680470</td>\n",
       "      <td>-0.039263</td>\n",
       "      <td>0.30186</td>\n",
       "      <td>-0.17792</td>\n",
       "      <td>0.42962</td>\n",
       "      <td>0.032246</td>\n",
       "      <td>-0.41376</td>\n",
       "      <td>0.13228</td>\n",
       "      <td>-0.29847</td>\n",
       "      <td>-0.085253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094375</td>\n",
       "      <td>0.018324</td>\n",
       "      <td>0.210480</td>\n",
       "      <td>-0.030880</td>\n",
       "      <td>-0.19722</td>\n",
       "      <td>0.082279</td>\n",
       "      <td>-0.094340</td>\n",
       "      <td>-0.073297</td>\n",
       "      <td>-0.064699</td>\n",
       "      <td>-0.26044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2        3        4        5         6        7   \\\n",
       "0                                                                       \n",
       "the  0.418000  0.249680 -0.41242  0.12170  0.34527 -0.044457 -0.49688   \n",
       ",    0.013441  0.236820 -0.16899  0.40951  0.63812  0.477090 -0.42852   \n",
       ".    0.151640  0.301770 -0.16763  0.17684  0.31719  0.339730 -0.43478   \n",
       "of   0.708530  0.570880 -0.47160  0.18048  0.54449  0.726030  0.18157   \n",
       "to   0.680470 -0.039263  0.30186 -0.17792  0.42962  0.032246 -0.41376   \n",
       "\n",
       "          8        9         10  ...        41        42        43        44  \\\n",
       "0                                ...                                           \n",
       "the -0.17862 -0.00066 -0.656600  ... -0.298710 -0.157490 -0.347580 -0.045637   \n",
       ",   -0.55641 -0.36400 -0.239380  ... -0.080262  0.630030  0.321110 -0.467650   \n",
       ".   -0.31086 -0.44999 -0.294860  ... -0.000064  0.068987  0.087939 -0.102850   \n",
       "of  -0.52393  0.10381 -0.175660  ... -0.347270  0.284830  0.075693 -0.062178   \n",
       "to   0.13228 -0.29847 -0.085253  ... -0.094375  0.018324  0.210480 -0.030880   \n",
       "\n",
       "          45        46        47        48        49       50  \n",
       "0                                                              \n",
       "the -0.44251  0.187850  0.002785 -0.184110 -0.115140 -0.78581  \n",
       ",    0.22786  0.360340 -0.378180 -0.566570  0.044691  0.30392  \n",
       ".   -0.13931  0.223140 -0.080803 -0.356520  0.016413  0.10216  \n",
       "of  -0.38988  0.229020 -0.216170 -0.225620 -0.093918 -0.80375  \n",
       "to  -0.19722  0.082279 -0.094340 -0.073297 -0.064699 -0.26044  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'glove.6B.50d.txt'), header=None, index_col=0, sep=None, error_bad_lines=False, encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full size of Glove: 399694\n",
      "Size after only considering the most common words: (3595, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Full size of Glove: {}\".format(df.shape[0]))\n",
    "df_common = df.loc[df.index.isin(most_common_words)]\n",
    "print(\"Size after only considering the most common words: {}\".format(df_common.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing the word vectors in order to be projected on TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3595, 50)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.plugins import projector\n",
    "\n",
    "log_dir=os.path.join('logs', 'embeddings')\n",
    "# Save the weights we want to analyse as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, so\n",
    "# we will remove that value.\n",
    "weights = tf.Variable(df_common.values)\n",
    "print(weights.shape)\n",
    "# Create a checkpoint from embedding, the filename and key are\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), 'w') as f:\n",
    "    for w in df_common.index:\n",
    "        f.write(w+'\\n')\n",
    "        \n",
    "# Set up config\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "#embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIsualizing/highlighting word vecs\n",
    "# (?:fred|larry|mrs\\.|mr\\.|michelle|sea|denzel|beach|comedy|theater|idiotic|sadistic|marvelous|loving|gorg|bus|truck|lugosi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-23 07:37:31.354360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/embeddings/ --port 6007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Open [Tensorboard for Word Vectors](http://localhost:6007) in the browser\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
