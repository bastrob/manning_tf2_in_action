{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Keras and Data Retrieval in TensorFlow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/manning_tf2_in_action/blob/master/Ch03-Keras-and-Data-Retrieval/3.2.Creating_Input_Pipelines.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "fix_random_seed(4321)\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `tf.data` API to retrieve data\n",
    "\n",
    "Here we will be using the `tf.data` API to feed a dataset containing images of flowers. The dataset has a folder containing the images and a CSV file listing filenames and their corresponding label as an integer. We will write a TensorFlow data pipeline that does the following.\n",
    "\n",
    "* Extract filenames and classes from the CSV\n",
    "* Read in the images from the extracted filenames and resize them to 64x64\n",
    "* Convert the class labels to one-hot encoded vectors\n",
    "* Combine the processed images and one-hot encoded vectors to a single dataset\n",
    "* Finally, shuffle the data and output as batches\n",
    "\n",
    "### Downloading the data\n",
    "The dataset is available at https://www.kaggle.com/olgabelitskaya/flower-color-images/data . \n",
    "\n",
    "You need to download the zip file available in this URL and place it in the `data` folder in the `Ch03-Keras-and-Data-Retrieval` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3.2\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Extracting the flowers image data to a directory\n",
    "zip_filepath = [os.path.join('data',f) for f in os.listdir('data') if f.endswith('.zip')]\n",
    "\n",
    "if len(zip_filepath)==0:\n",
    "    print(\"Did you download the dataset as a zip file and place it in the Ch03-Keras-and-Data-Retrieval/data folder?\")\n",
    "elif len(zip_filepath)>1:\n",
    "    print(\"There's too many .zip files. There should be only 1\")\n",
    "\n",
    "zfile = ZipFile(zip_filepath[0])\n",
    "zfile.extractall('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tf.data.Dataset \n",
    "\n",
    "Here we are creating the `tf.data` pipeline that executes the above steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image dataset contains: <MapDataset shapes: (64, 64, 3), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "# Section 3.2\n",
    "# Code listing 3.5\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session() # Making sure we are clearing out the TensorFlow graph\n",
    "\n",
    "# Read the CSV file with TensorFlow\n",
    "# The os.path.sep at the end is important for the get_image function\n",
    "data_dir = os.path.join('data','flower_images', 'flower_images') + os.path.sep\n",
    "assert os.path.exists(data_dir)\n",
    "csv_ds = tf.data.experimental.CsvDataset(\n",
    "    os.path.join(data_dir,'flower_labels.csv') , (\"\",-1), header=True\n",
    ")\n",
    "# Separate the image names and labels to two separate sets\n",
    "fname_ds = csv_ds.map(lambda a,b: a)\n",
    "label_ds = csv_ds.map(lambda a,b: b)\n",
    "\n",
    "def get_image(file_path):\n",
    "    \n",
    "    img = tf.io.read_file(data_dir + file_path)\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [64, 64])\n",
    "\n",
    "# Get the images by running get_image across all the filenames\n",
    "image_ds = fname_ds.map(get_image)\n",
    "print(\"The image dataset contains: {}\".format(image_ds))\n",
    "# Create onehot encoded labels from label data\n",
    "label_ds = label_ds.map(lambda x: tf.one_hot(x, depth=10))\n",
    "# Zip the images and labels together\n",
    "data_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "# Shuffle the data so that we get a mix of labels in every batch\n",
    "data_ds = data_ds.shuffle(buffer_size= 20)\n",
    "# Define a batch of size 5 \n",
    "data_ds = data_ds.batch(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(5, 64, 64, 3), dtype=float32, numpy=\n",
      "array([[[[0.05490196, 0.06960785, 0.0509804 ],\n",
      "         [0.05      , 0.06176471, 0.04803922],\n",
      "         [0.05882353, 0.07058824, 0.0509804 ],\n",
      "         ...,\n",
      "         [0.67352945, 0.67941177, 0.67352945],\n",
      "         [0.6245098 , 0.6343137 , 0.62647057],\n",
      "         [0.5588235 , 0.577451  , 0.5803922 ]],\n",
      "\n",
      "        [[0.0627451 , 0.07941177, 0.05588236],\n",
      "         [0.04509804, 0.05686275, 0.04313726],\n",
      "         [0.05490196, 0.06666667, 0.04607844],\n",
      "         ...,\n",
      "         [0.7019608 , 0.70490193, 0.70392156],\n",
      "         [0.6911765 , 0.70000005, 0.6882353 ],\n",
      "         [0.73529416, 0.7431373 , 0.74705887]],\n",
      "\n",
      "        [[0.05882353, 0.07352941, 0.05392157],\n",
      "         [0.03921569, 0.05      , 0.03921569],\n",
      "         [0.05686275, 0.06862745, 0.0509804 ],\n",
      "         ...,\n",
      "         [0.7107844 , 0.71470594, 0.71274513],\n",
      "         [0.8078432 , 0.8078432 , 0.8196079 ],\n",
      "         [0.84215695, 0.8343138 , 0.8352942 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.32352942, 0.34705883, 0.3137255 ],\n",
      "         [0.36764708, 0.38725492, 0.32254905],\n",
      "         [0.3147059 , 0.34117648, 0.3127451 ],\n",
      "         ...,\n",
      "         [0.15196079, 0.22941178, 0.08431373],\n",
      "         [0.20294118, 0.29607844, 0.10980393],\n",
      "         [0.30686277, 0.42058825, 0.127451  ]],\n",
      "\n",
      "        [[0.29901963, 0.33039218, 0.28235295],\n",
      "         [0.34117648, 0.35882354, 0.30882353],\n",
      "         [0.29803923, 0.327451  , 0.2735294 ],\n",
      "         ...,\n",
      "         [0.16568628, 0.23529413, 0.07745098],\n",
      "         [0.18529414, 0.28039217, 0.10588236],\n",
      "         [0.24117649, 0.3480392 , 0.12843138]],\n",
      "\n",
      "        [[0.29607844, 0.32352942, 0.2735294 ],\n",
      "         [0.31764707, 0.3392157 , 0.28921568],\n",
      "         [0.3       , 0.3254902 , 0.25588238],\n",
      "         ...,\n",
      "         [0.20490196, 0.3009804 , 0.07647059],\n",
      "         [0.17058824, 0.24901962, 0.0754902 ],\n",
      "         [0.29411766, 0.3686275 , 0.14803922]]],\n",
      "\n",
      "\n",
      "       [[[0.02941177, 0.02941177, 0.02745098],\n",
      "         [0.04117648, 0.05      , 0.03921569],\n",
      "         [0.14019608, 0.17843139, 0.11176471],\n",
      "         ...,\n",
      "         [0.0254902 , 0.0254902 , 0.0254902 ],\n",
      "         [0.0254902 , 0.0254902 , 0.0254902 ],\n",
      "         [0.02450981, 0.02450981, 0.02450981]],\n",
      "\n",
      "        [[0.04411765, 0.04901961, 0.0382353 ],\n",
      "         [0.13333334, 0.16960785, 0.10490197],\n",
      "         [0.19901963, 0.2735294 , 0.15490197],\n",
      "         ...,\n",
      "         [0.0254902 , 0.0254902 , 0.0254902 ],\n",
      "         [0.02647059, 0.02647059, 0.02647059],\n",
      "         [0.02647059, 0.02745098, 0.0254902 ]],\n",
      "\n",
      "        [[0.12254903, 0.1637255 , 0.09509805],\n",
      "         [0.20686276, 0.2901961 , 0.15490197],\n",
      "         [0.1892157 , 0.27549022, 0.14803922],\n",
      "         ...,\n",
      "         [0.02843137, 0.02941177, 0.02843137],\n",
      "         [0.02843137, 0.03333334, 0.02843137],\n",
      "         [0.0382353 , 0.04411765, 0.03431373]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.88039225, 0.6186274 , 0.72745097],\n",
      "         [0.71274513, 0.47058827, 0.6009804 ],\n",
      "         [0.5254902 , 0.3156863 , 0.44705886],\n",
      "         ...,\n",
      "         [0.05686275, 0.07941177, 0.04705883],\n",
      "         [0.04901961, 0.05784314, 0.04019608],\n",
      "         [0.02450981, 0.0254902 , 0.0254902 ]],\n",
      "\n",
      "        [[0.9235295 , 0.7156863 , 0.75686276],\n",
      "         [0.60882354, 0.3892157 , 0.37549022],\n",
      "         [0.68921566, 0.50784314, 0.58921576],\n",
      "         ...,\n",
      "         [0.06862745, 0.09411766, 0.05392157],\n",
      "         [0.03039216, 0.03529412, 0.02941177],\n",
      "         [0.02450981, 0.02352941, 0.02450981]],\n",
      "\n",
      "        [[0.8264707 , 0.6578431 , 0.7029412 ],\n",
      "         [0.51176476, 0.46078432, 0.43529415],\n",
      "         [0.29705885, 0.35000002, 0.22941178],\n",
      "         ...,\n",
      "         [0.07352941, 0.09509805, 0.05882353],\n",
      "         [0.02352941, 0.02254902, 0.02450981],\n",
      "         [0.0254902 , 0.0254902 , 0.0254902 ]]],\n",
      "\n",
      "\n",
      "       [[[0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01372549, 0.01372549, 0.01372549],\n",
      "         ...,\n",
      "         [0.2401961 , 0.2392157 , 0.3147059 ],\n",
      "         [0.04607844, 0.04019608, 0.04019608],\n",
      "         [0.03235294, 0.03235294, 0.03235294]],\n",
      "\n",
      "        [[0.00882353, 0.00882353, 0.00882353],\n",
      "         [0.0127451 , 0.0127451 , 0.01176471],\n",
      "         [0.02450981, 0.02156863, 0.0254902 ],\n",
      "         ...,\n",
      "         [0.29509807, 0.26666668, 0.29803926],\n",
      "         [0.08235295, 0.06862745, 0.08333334],\n",
      "         [0.04705883, 0.04705883, 0.04803922]],\n",
      "\n",
      "        [[0.01078431, 0.01078431, 0.01078431],\n",
      "         [0.01960785, 0.01568628, 0.01862745],\n",
      "         [0.3137255 , 0.29509807, 0.31960785],\n",
      "         ...,\n",
      "         [0.41274512, 0.3686275 , 0.39411768],\n",
      "         [0.29215688, 0.26666668, 0.29607844],\n",
      "         [0.05686275, 0.05980393, 0.05882353]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.03235294, 0.03235294, 0.03235294],\n",
      "         [0.02156863, 0.02156863, 0.02156863],\n",
      "         [0.03039216, 0.03039216, 0.03039216],\n",
      "         ...,\n",
      "         [0.01078431, 0.01078431, 0.01078431],\n",
      "         [0.02745098, 0.02745098, 0.02745098],\n",
      "         [0.04803922, 0.05      , 0.04705883]],\n",
      "\n",
      "        [[0.02058824, 0.02058824, 0.02058824],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.01372549, 0.01372549, 0.01372549],\n",
      "         ...,\n",
      "         [0.02254902, 0.02254902, 0.02254902],\n",
      "         [0.04117648, 0.04313726, 0.03921569],\n",
      "         [0.0509804 , 0.05490196, 0.04509804]],\n",
      "\n",
      "        [[0.01078431, 0.01078431, 0.01078431],\n",
      "         [0.00882353, 0.00882353, 0.00882353],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         ...,\n",
      "         [0.02941177, 0.02941177, 0.02745098],\n",
      "         [0.04607844, 0.04607844, 0.03921569],\n",
      "         [0.03627451, 0.0372549 , 0.03431373]]],\n",
      "\n",
      "\n",
      "       [[[0.28921568, 0.26568627, 0.23431374],\n",
      "         [0.28333336, 0.31764707, 0.21960786],\n",
      "         [0.25980395, 0.31078434, 0.19509806],\n",
      "         ...,\n",
      "         [0.22843139, 0.2137255 , 0.18725492],\n",
      "         [0.28431374, 0.25980395, 0.22450982],\n",
      "         [0.3147059 , 0.27450982, 0.21960786]],\n",
      "\n",
      "        [[0.34411764, 0.31862748, 0.28333336],\n",
      "         [0.33529413, 0.34509805, 0.26372552],\n",
      "         [0.26862746, 0.30686277, 0.19607845],\n",
      "         ...,\n",
      "         [0.28725493, 0.27156866, 0.2137255 ],\n",
      "         [0.31666666, 0.29607844, 0.21764708],\n",
      "         [0.23235296, 0.2137255 , 0.15784314]],\n",
      "\n",
      "        [[0.32254905, 0.33333334, 0.2617647 ],\n",
      "         [0.29901963, 0.33333334, 0.23823531],\n",
      "         [0.23725492, 0.29803923, 0.17843139],\n",
      "         ...,\n",
      "         [0.28529412, 0.28333336, 0.18431374],\n",
      "         [0.18039218, 0.18333334, 0.13039216],\n",
      "         [0.13431373, 0.1382353 , 0.11568628]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980393, 0.19313727, 0.07058824],\n",
      "         [0.11176471, 0.2029412 , 0.07647059],\n",
      "         [0.1137255 , 0.20980394, 0.08039216],\n",
      "         ...,\n",
      "         [0.14705883, 0.14411765, 0.1264706 ],\n",
      "         [0.1254902 , 0.1254902 , 0.11274511],\n",
      "         [0.1382353 , 0.1392157 , 0.1264706 ]],\n",
      "\n",
      "        [[0.20098041, 0.21666668, 0.15      ],\n",
      "         [0.17156863, 0.20784315, 0.1264706 ],\n",
      "         [0.13431373, 0.20490198, 0.09901962],\n",
      "         ...,\n",
      "         [0.15196079, 0.14901961, 0.12941177],\n",
      "         [0.13725491, 0.13529412, 0.12156864],\n",
      "         [0.14705883, 0.15      , 0.13431373]],\n",
      "\n",
      "        [[0.23627453, 0.21176472, 0.18235296],\n",
      "         [0.19215688, 0.17843139, 0.15882353],\n",
      "         [0.15196079, 0.15294118, 0.1264706 ],\n",
      "         ...,\n",
      "         [0.14215687, 0.1392157 , 0.12156864],\n",
      "         [0.1382353 , 0.13529412, 0.12058824],\n",
      "         [0.13333334, 0.13529412, 0.11960785]]],\n",
      "\n",
      "\n",
      "       [[[0.04117648, 0.04117648, 0.03627452],\n",
      "         [0.0382353 , 0.04117647, 0.03333334],\n",
      "         [0.00980392, 0.00784314, 0.01176471],\n",
      "         ...,\n",
      "         [0.02647059, 0.03235294, 0.02352941],\n",
      "         [0.02745098, 0.03529412, 0.02647059],\n",
      "         [0.02156863, 0.02156863, 0.02156863]],\n",
      "\n",
      "        [[0.04215687, 0.04215687, 0.03333334],\n",
      "         [0.05980393, 0.06470589, 0.04705883],\n",
      "         [0.01078431, 0.01078431, 0.01176471],\n",
      "         ...,\n",
      "         [0.02647059, 0.02941177, 0.02156863],\n",
      "         [0.02745098, 0.0382353 , 0.0254902 ],\n",
      "         [0.0254902 , 0.02450981, 0.02254902]],\n",
      "\n",
      "        [[0.05      , 0.05196079, 0.04215687],\n",
      "         [0.03333334, 0.03235295, 0.02941177],\n",
      "         [0.01078431, 0.01078431, 0.01078431],\n",
      "         ...,\n",
      "         [0.02254902, 0.02156863, 0.01960785],\n",
      "         [0.03137255, 0.04215686, 0.03039216],\n",
      "         [0.03235294, 0.04019608, 0.02843137]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.09509805, 0.13039216, 0.06372549],\n",
      "         [0.01764706, 0.02156863, 0.01470588],\n",
      "         [0.00686275, 0.00588235, 0.00588235],\n",
      "         ...,\n",
      "         [0.02058824, 0.01960784, 0.01960784],\n",
      "         [0.0254902 , 0.0254902 , 0.02352941],\n",
      "         [0.04803922, 0.05196079, 0.04313726]],\n",
      "\n",
      "        [[0.07745099, 0.10686275, 0.05      ],\n",
      "         [0.07843138, 0.11274511, 0.05196079],\n",
      "         [0.00490196, 0.00392157, 0.00588235],\n",
      "         ...,\n",
      "         [0.01764706, 0.01764706, 0.01764706],\n",
      "         [0.02156863, 0.02058824, 0.02058824],\n",
      "         [0.01862745, 0.01862745, 0.01862745]],\n",
      "\n",
      "        [[0.14117648, 0.20784315, 0.06372549],\n",
      "         [0.12843138, 0.18431374, 0.06176471],\n",
      "         [0.07352942, 0.10882354, 0.04901961],\n",
      "         ...,\n",
      "         [0.0127451 , 0.0127451 , 0.0127451 ],\n",
      "         [0.01372549, 0.01372549, 0.01372549],\n",
      "         [0.00882353, 0.00784314, 0.00784314]]]], dtype=float32)>, <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
      "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the data to see what it contains\n",
    "for item in data_ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training a model\n",
    "\n",
    "Here we are defining a simple Convolution Neural Network (CNN) model to train it on the image data we just retrieved. You don't have to worry about the technical details of CNNs right now. We will discuss them in detail in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.8892 - acc: 0.2571\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 1.2810 - acc: 0.5905\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.5905 - acc: 0.8381\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.2453 - acc: 0.9524\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.1216 - acc: 0.9476\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.0322 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 8.8022e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdfc219080>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 3.2\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Defining a Convolution neural network for you to train for the flowers data\n",
    "# We will discuss convolution neural networks in more detail later\n",
    "model = Sequential([\n",
    "    Conv2D(64,(5,5), activation='relu', input_shape=(64,64,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# Training the model with the tf.data pipeline\n",
    "model.fit(data_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras data generators to retrieve data\n",
    "\n",
    "Instead of `tf.data` API let us use the Keras `ImageDataGenerator` to retrieve the data. As you can see, the `ImageDataGenerator` involves much less code than the using the `tf.data` API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 validated image filenames.\n",
      "(array([[[[ 43.,  53.,  43.],\n",
      "         [ 50.,  57.,  49.],\n",
      "         [ 55.,  64.,  51.],\n",
      "         ...,\n",
      "         [ 61.,  97.,  38.],\n",
      "         [ 60.,  94.,  37.],\n",
      "         [ 60.,  92.,  42.]],\n",
      "\n",
      "        [[ 56.,  64.,  56.],\n",
      "         [ 59.,  68.,  57.],\n",
      "         [ 59.,  72.,  56.],\n",
      "         ...,\n",
      "         [ 61.,  98.,  32.],\n",
      "         [ 66., 102.,  39.],\n",
      "         [ 66.,  95.,  44.]],\n",
      "\n",
      "        [[ 60.,  73.,  59.],\n",
      "         [ 57.,  68.,  56.],\n",
      "         [ 61.,  71.,  56.],\n",
      "         ...,\n",
      "         [ 66., 105.,  32.],\n",
      "         [ 70., 105.,  38.],\n",
      "         [ 61.,  94.,  40.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 22.,  26.,  21.],\n",
      "         [ 20.,  25.,  20.],\n",
      "         [ 27.,  35.,  25.],\n",
      "         ...,\n",
      "         [ 49.,  79.,  38.],\n",
      "         [ 56.,  77.,  39.],\n",
      "         [ 54.,  70.,  41.]],\n",
      "\n",
      "        [[ 22.,  27.,  21.],\n",
      "         [  0.,   0.,   0.],\n",
      "         [ 49.,  62.,  43.],\n",
      "         ...,\n",
      "         [ 68.,  97.,  51.],\n",
      "         [ 78., 105.,  61.],\n",
      "         [ 70.,  87.,  54.]],\n",
      "\n",
      "        [[105., 129.,  97.],\n",
      "         [107., 139., 103.],\n",
      "         [ 39.,  63.,  37.],\n",
      "         ...,\n",
      "         [ 83., 115.,  62.],\n",
      "         [102., 128.,  81.],\n",
      "         [ 89., 113.,  78.]]],\n",
      "\n",
      "\n",
      "       [[[ 24.,  44.,  16.],\n",
      "         [ 22.,  31.,  16.],\n",
      "         [ 39.,  45.,  25.],\n",
      "         ...,\n",
      "         [ 33.,  50.,  27.],\n",
      "         [ 32.,  46.,  27.],\n",
      "         [ 35.,  51.,  27.]],\n",
      "\n",
      "        [[ 25.,  45.,  15.],\n",
      "         [ 27.,  45.,  15.],\n",
      "         [ 25.,  32.,  18.],\n",
      "         ...,\n",
      "         [ 27.,  37.,  21.],\n",
      "         [  6.,  10.,   8.],\n",
      "         [  9.,  12.,   9.]],\n",
      "\n",
      "        [[ 24.,  45.,  14.],\n",
      "         [ 21.,  39.,  12.],\n",
      "         [ 23.,  35.,  17.],\n",
      "         ...,\n",
      "         [ 35.,  49.,  30.],\n",
      "         [ 18.,  23.,  16.],\n",
      "         [ 14.,  16.,  13.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  8.,   8.,   7.],\n",
      "         [  7.,   8.,   7.],\n",
      "         [ 10.,  12.,   9.],\n",
      "         ...,\n",
      "         [  8.,  10.,   7.],\n",
      "         [  7.,  10.,   7.],\n",
      "         [  7.,  11.,   7.]],\n",
      "\n",
      "        [[  7.,   9.,   8.],\n",
      "         [  7.,  10.,   7.],\n",
      "         [ 12.,  13.,  12.],\n",
      "         ...,\n",
      "         [ 10.,  11.,   9.],\n",
      "         [ 10.,  12.,  11.],\n",
      "         [ 17.,  27.,  13.]],\n",
      "\n",
      "        [[  5.,   7.,   6.],\n",
      "         [  9.,  12.,   8.],\n",
      "         [ 16.,  23.,  14.],\n",
      "         ...,\n",
      "         [ 11.,  12.,  11.],\n",
      "         [ 18.,  27.,  14.],\n",
      "         [ 27.,  49.,  18.]]],\n",
      "\n",
      "\n",
      "       [[[ 32.,  43.,  35.],\n",
      "         [ 13.,  19.,  13.],\n",
      "         [ 13.,  21.,  14.],\n",
      "         ...,\n",
      "         [ 25.,  38.,  16.],\n",
      "         [ 29.,  42.,  34.],\n",
      "         [ 35.,  51.,  28.]],\n",
      "\n",
      "        [[ 25.,  35.,  28.],\n",
      "         [ 16.,  18.,  13.],\n",
      "         [  9.,   7.,   8.],\n",
      "         ...,\n",
      "         [ 31.,  43.,  33.],\n",
      "         [ 34.,  48.,  31.],\n",
      "         [ 20.,  27.,  14.]],\n",
      "\n",
      "        [[ 26.,  34.,  26.],\n",
      "         [ 14.,  16.,  12.],\n",
      "         [ 26.,  36.,  27.],\n",
      "         ...,\n",
      "         [ 31.,  41.,  22.],\n",
      "         [ 31.,  48.,  23.],\n",
      "         [ 28.,  42.,  23.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 25.,  31.,  15.],\n",
      "         [ 14.,  23.,  12.],\n",
      "         [ 23.,  39.,  22.],\n",
      "         ...,\n",
      "         [ 17.,  26.,  16.],\n",
      "         [  8.,   9.,   7.],\n",
      "         [ 11.,  13.,  10.]],\n",
      "\n",
      "        [[ 19.,  29.,  13.],\n",
      "         [ 19.,  28.,  16.],\n",
      "         [ 28.,  42.,  26.],\n",
      "         ...,\n",
      "         [ 17.,  26.,  16.],\n",
      "         [ 10.,  11.,   8.],\n",
      "         [  5.,   5.,   5.]],\n",
      "\n",
      "        [[ 26.,  40.,  24.],\n",
      "         [ 31.,  41.,  21.],\n",
      "         [ 27.,  37.,  25.],\n",
      "         ...,\n",
      "         [ 15.,  20.,  14.],\n",
      "         [  8.,   8.,   7.],\n",
      "         [  7.,   7.,   6.]]],\n",
      "\n",
      "\n",
      "       [[[ 86.,  90.,  87.],\n",
      "         [ 45.,  52.,  44.],\n",
      "         [  5.,   4.,   3.],\n",
      "         ...,\n",
      "         [  9.,   9.,   9.],\n",
      "         [  9.,   9.,   9.],\n",
      "         [  9.,   9.,   9.]],\n",
      "\n",
      "        [[ 24.,  28.,  24.],\n",
      "         [  8.,  10.,   9.],\n",
      "         [  8.,   8.,   8.],\n",
      "         ...,\n",
      "         [  6.,   6.,   6.],\n",
      "         [  8.,   8.,   8.],\n",
      "         [ 10.,  10.,  10.]],\n",
      "\n",
      "        [[ 41.,  39.,  43.],\n",
      "         [ 45.,  43.,  47.],\n",
      "         [ 30.,  29.,  31.],\n",
      "         ...,\n",
      "         [  5.,   5.,   5.],\n",
      "         [  6.,   6.,   6.],\n",
      "         [  7.,   7.,   7.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  9.,   9.,   9.],\n",
      "         [  9.,   9.,   9.],\n",
      "         [ 10.,  10.,  10.],\n",
      "         ...,\n",
      "         [ 15.,  15.,  14.],\n",
      "         [ 12.,  12.,  12.],\n",
      "         [ 11.,  11.,  11.]],\n",
      "\n",
      "        [[ 10.,  10.,  10.],\n",
      "         [ 12.,  12.,  12.],\n",
      "         [ 13.,  13.,  13.],\n",
      "         ...,\n",
      "         [ 19.,  20.,  17.],\n",
      "         [ 11.,  11.,  11.],\n",
      "         [ 12.,  12.,  12.]],\n",
      "\n",
      "        [[  8.,   8.,   8.],\n",
      "         [ 10.,  10.,  10.],\n",
      "         [ 19.,  19.,  19.],\n",
      "         ...,\n",
      "         [  4.,   4.,   4.],\n",
      "         [ 10.,  10.,  10.],\n",
      "         [ 10.,  10.,  10.]]],\n",
      "\n",
      "\n",
      "       [[[ 12.,  13.,  14.],\n",
      "         [ 13.,  13.,  15.],\n",
      "         [ 13.,  14.,  15.],\n",
      "         ...,\n",
      "         [ 15.,  15.,  13.],\n",
      "         [ 16.,  15.,  13.],\n",
      "         [ 16.,  15.,  14.]],\n",
      "\n",
      "        [[ 10.,  10.,  10.],\n",
      "         [ 10.,  10.,  10.],\n",
      "         [ 11.,  11.,  11.],\n",
      "         ...,\n",
      "         [ 12.,  11.,  12.],\n",
      "         [ 13.,  13.,  13.],\n",
      "         [ 13.,  13.,  13.]],\n",
      "\n",
      "        [[  4.,   4.,   4.],\n",
      "         [  4.,   4.,   4.],\n",
      "         [  4.,   4.,   4.],\n",
      "         ...,\n",
      "         [ 12.,  11.,  12.],\n",
      "         [ 11.,  11.,  11.],\n",
      "         [ 11.,  11.,  11.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[173., 127., 122.],\n",
      "         [164., 119., 114.],\n",
      "         [157., 115., 108.],\n",
      "         ...,\n",
      "         [116., 115., 103.],\n",
      "         [102., 103.,  92.],\n",
      "         [124., 116.,  98.]],\n",
      "\n",
      "        [[169., 125., 118.],\n",
      "         [146., 119., 108.],\n",
      "         [147., 124., 112.],\n",
      "         ...,\n",
      "         [ 85.,  80.,  75.],\n",
      "         [155., 146., 137.],\n",
      "         [170., 156., 138.]],\n",
      "\n",
      "        [[166., 129., 122.],\n",
      "         [130., 114.,  97.],\n",
      "         [115., 120.,  87.],\n",
      "         ...,\n",
      "         [133., 125., 105.],\n",
      "         [127., 115., 104.],\n",
      "         [113.,  98.,  91.]]]], dtype=float32), array([7, 0, 4, 4, 5]))\n"
     ]
    }
   ],
   "source": [
    "# Section 3.2\n",
    "# Code listing 3.6\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join('data','flower_images', 'flower_images')\n",
    "\n",
    "# Defining an image data generator provided in Keras\n",
    "img_gen = ImageDataGenerator()\n",
    "\n",
    "# Reading the CSV files containing filenames and labels\n",
    "labels_df = pd.read_csv(os.path.join(data_dir, 'flower_labels.csv'), header=0)\n",
    "\n",
    "# Generating data using the flow_from_dataframe function\n",
    "gen_iter = img_gen.flow_from_dataframe(\n",
    "    dataframe=labels_df, directory=data_dir, x_col='file', y_col='label', class_mode='raw', batch_size=5, target_size=(64,64))\n",
    "\n",
    "# Iterating through the data\n",
    "for item in gen_iter:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `tensorflow-datasets` library\n",
    "\n",
    "Here we will use the `tensorflow-datasets` package. It is a curated list of popular datasets available for machine learning projects. With this package you can download a dataset in a single line. This means you don't have to worry about downloading/extracting/formatting data manually. All of that will be already done when you import data using the `tensorflow-datasets` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists the available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'blimp',\n",
       " 'bool_q',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'coqa',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'downsampled_imagenet',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gpt3',\n",
       " 'groove',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'i_naturalist2017',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mctaco',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quickdraw_bitmap',\n",
       " 'radon',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'resisc45',\n",
       " 'robonet',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vctk',\n",
       " 'vgg_face2',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_questions',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_bio',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 3.2\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "# See all registered datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Cifar10 dataset and view information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    version=3.0.2,\n",
      "    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\n",
      "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
      "    features=FeaturesDict({\n",
      "        'id': Text(shape=(), dtype=tf.string),\n",
      "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    total_num_examples=60000,\n",
      "    splits={\n",
      "        'test': 10000,\n",
      "        'train': 50000,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Section 3.2\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session() # Making sure we are clearing out the TensorFlow graph\n",
    "\n",
    "# Load a given dataset by name, along with the DatasetInfo\n",
    "data, info = tfds.load(\"cifar10\", with_info=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data \n",
    "\n",
    "Here we will print the `data` and see what it provides. Then we will need to batch the data as data is provided as individual samples when you import it from `tensorflow-datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': <PrefetchDataset shapes: {id: (), image: (32, 32, 3), label: ()}, types: {id: tf.string, image: tf.uint8, label: tf.int64}>, 'train': <PrefetchDataset shapes: {id: (), image: (32, 32, 3), label: ()}, types: {id: tf.string, image: tf.uint8, label: tf.int64}>}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': <tf.Tensor: shape=(16,), dtype=string, numpy=\n",
      "array([b'train_16399', b'train_01680', b'train_47917', b'train_17307',\n",
      "       b'train_27051', b'train_48736', b'train_26263', b'train_01456',\n",
      "       b'train_19135', b'train_31598', b'train_12970', b'train_04223',\n",
      "       b'train_27152', b'train_49635', b'train_04093', b'train_17537'],\n",
      "      dtype=object)>, 'image': <tf.Tensor: shape=(16, 32, 32, 3), dtype=uint8, numpy=\n",
      "array([[[[143,  96,  70],\n",
      "         [141,  96,  72],\n",
      "         [135,  93,  72],\n",
      "         ...,\n",
      "         [ 96,  37,  19],\n",
      "         [105,  42,  18],\n",
      "         [104,  38,  20]],\n",
      "\n",
      "        [[128,  98,  92],\n",
      "         [146, 118, 112],\n",
      "         [170, 145, 138],\n",
      "         ...,\n",
      "         [108,  45,  26],\n",
      "         [112,  44,  24],\n",
      "         [112,  41,  22]],\n",
      "\n",
      "        [[ 93,  69,  75],\n",
      "         [118,  96, 101],\n",
      "         [179, 160, 162],\n",
      "         ...,\n",
      "         [128,  68,  47],\n",
      "         [125,  61,  42],\n",
      "         [122,  59,  39]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[187, 150, 123],\n",
      "         [184, 148, 123],\n",
      "         [179, 142, 121],\n",
      "         ...,\n",
      "         [198, 163, 132],\n",
      "         [201, 166, 135],\n",
      "         [207, 174, 143]],\n",
      "\n",
      "        [[187, 150, 117],\n",
      "         [181, 143, 115],\n",
      "         [175, 136, 113],\n",
      "         ...,\n",
      "         [201, 164, 132],\n",
      "         [205, 168, 135],\n",
      "         [207, 171, 139]],\n",
      "\n",
      "        [[195, 161, 126],\n",
      "         [187, 153, 123],\n",
      "         [186, 151, 128],\n",
      "         ...,\n",
      "         [212, 177, 147],\n",
      "         [219, 185, 155],\n",
      "         [221, 187, 157]]],\n",
      "\n",
      "\n",
      "       [[[203, 214, 234],\n",
      "         [191, 207, 226],\n",
      "         [178, 200, 224],\n",
      "         ...,\n",
      "         [127, 172, 213],\n",
      "         [126, 171, 212],\n",
      "         [124, 170, 211]],\n",
      "\n",
      "        [[205, 214, 230],\n",
      "         [186, 199, 213],\n",
      "         [180, 197, 214],\n",
      "         ...,\n",
      "         [132, 178, 219],\n",
      "         [130, 176, 219],\n",
      "         [129, 175, 217]],\n",
      "\n",
      "        [[193, 200, 213],\n",
      "         [141, 151, 159],\n",
      "         [124, 137, 145],\n",
      "         ...,\n",
      "         [136, 178, 218],\n",
      "         [134, 177, 218],\n",
      "         [132, 176, 217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 40,  47,  56],\n",
      "         [ 33,  37,  42],\n",
      "         [ 31,  35,  41],\n",
      "         ...,\n",
      "         [ 73,  99, 132],\n",
      "         [ 64,  91, 126],\n",
      "         [ 69,  97, 133]],\n",
      "\n",
      "        [[ 37,  44,  53],\n",
      "         [ 31,  34,  40],\n",
      "         [ 30,  34,  40],\n",
      "         ...,\n",
      "         [ 72,  98, 132],\n",
      "         [ 64,  92, 127],\n",
      "         [ 68,  96, 132]],\n",
      "\n",
      "        [[ 34,  41,  50],\n",
      "         [ 29,  32,  38],\n",
      "         [ 28,  32,  38],\n",
      "         ...,\n",
      "         [ 68,  94, 127],\n",
      "         [ 62,  89, 123],\n",
      "         [ 63,  91, 126]]],\n",
      "\n",
      "\n",
      "       [[[106, 103, 104],\n",
      "         [103,  97,  99],\n",
      "         [102,  93,  96],\n",
      "         ...,\n",
      "         [135, 126, 129],\n",
      "         [139, 130, 133],\n",
      "         [131, 122, 125]],\n",
      "\n",
      "        [[106, 104, 105],\n",
      "         [105,  99, 101],\n",
      "         [115, 106, 109],\n",
      "         ...,\n",
      "         [137, 129, 132],\n",
      "         [135, 126, 129],\n",
      "         [124, 115, 118]],\n",
      "\n",
      "        [[108, 105, 106],\n",
      "         [117, 111, 113],\n",
      "         [123, 114, 117],\n",
      "         ...,\n",
      "         [132, 123, 126],\n",
      "         [126, 117, 120],\n",
      "         [121, 112, 115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[136, 163, 117],\n",
      "         [135, 162, 115],\n",
      "         [139, 166, 117],\n",
      "         ...,\n",
      "         [140, 144, 111],\n",
      "         [133, 135, 105],\n",
      "         [126, 125,  98]],\n",
      "\n",
      "        [[130, 150, 104],\n",
      "         [131, 150, 107],\n",
      "         [131, 150, 109],\n",
      "         ...,\n",
      "         [141, 150, 112],\n",
      "         [144, 152, 115],\n",
      "         [140, 144, 111]],\n",
      "\n",
      "        [[139, 151, 108],\n",
      "         [133, 144, 103],\n",
      "         [145, 156, 116],\n",
      "         ...,\n",
      "         [129, 137, 100],\n",
      "         [138, 144, 110],\n",
      "         [134, 136, 106]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[146, 149, 166],\n",
      "         [143, 147, 164],\n",
      "         [141, 144, 160],\n",
      "         ...,\n",
      "         [215, 194, 176],\n",
      "         [225, 204, 186],\n",
      "         [224, 203, 185]],\n",
      "\n",
      "        [[143, 149, 165],\n",
      "         [143, 148, 165],\n",
      "         [140, 144, 160],\n",
      "         ...,\n",
      "         [182, 164, 149],\n",
      "         [186, 168, 153],\n",
      "         [179, 161, 146]],\n",
      "\n",
      "        [[139, 144, 163],\n",
      "         [139, 144, 162],\n",
      "         [137, 142, 160],\n",
      "         ...,\n",
      "         [183, 161, 147],\n",
      "         [187, 165, 151],\n",
      "         [186, 164, 150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 70,  70,  85],\n",
      "         [ 69,  69,  83],\n",
      "         [ 67,  67,  81],\n",
      "         ...,\n",
      "         [ 81,  83,  99],\n",
      "         [ 81,  84,  99],\n",
      "         [ 73,  75,  91]],\n",
      "\n",
      "        [[ 72,  71,  85],\n",
      "         [ 70,  69,  83],\n",
      "         [ 68,  67,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  96],\n",
      "         [ 81,  83,  98],\n",
      "         [ 73,  75,  90]],\n",
      "\n",
      "        [[ 72,  72,  85],\n",
      "         [ 70,  70,  83],\n",
      "         [ 69,  69,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  95],\n",
      "         [ 81,  83,  97],\n",
      "         [ 73,  75,  89]]],\n",
      "\n",
      "\n",
      "       [[[133, 151, 172],\n",
      "         [129, 148, 172],\n",
      "         [131, 153, 173],\n",
      "         ...,\n",
      "         [226, 221, 211],\n",
      "         [228, 224, 215],\n",
      "         [218, 213, 207]],\n",
      "\n",
      "        [[135, 152, 174],\n",
      "         [130, 148, 174],\n",
      "         [132, 152, 176],\n",
      "         ...,\n",
      "         [215, 211, 201],\n",
      "         [213, 208, 200],\n",
      "         [203, 198, 193]],\n",
      "\n",
      "        [[142, 158, 179],\n",
      "         [133, 149, 177],\n",
      "         [131, 149, 175],\n",
      "         ...,\n",
      "         [206, 201, 194],\n",
      "         [203, 199, 193],\n",
      "         [197, 192, 188]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 82,  91,  97],\n",
      "         [ 92, 105, 109],\n",
      "         [ 92, 108, 118],\n",
      "         ...,\n",
      "         [ 86, 105, 113],\n",
      "         [ 92, 109, 116],\n",
      "         [ 90, 105, 114]],\n",
      "\n",
      "        [[ 88,  93,  99],\n",
      "         [ 96, 106, 110],\n",
      "         [ 94, 108, 117],\n",
      "         ...,\n",
      "         [ 87, 103, 117],\n",
      "         [ 91, 105, 115],\n",
      "         [ 91, 103, 116]],\n",
      "\n",
      "        [[ 88,  90,  97],\n",
      "         [ 94, 100, 105],\n",
      "         [ 91,  99, 108],\n",
      "         ...,\n",
      "         [ 89, 103, 117],\n",
      "         [ 87, 100, 111],\n",
      "         [ 90, 102, 114]]],\n",
      "\n",
      "\n",
      "       [[[ 75,  75,  80],\n",
      "         [ 75,  77,  81],\n",
      "         [ 81,  83,  88],\n",
      "         ...,\n",
      "         [ 71,  72,  70],\n",
      "         [ 68,  70,  68],\n",
      "         [ 68,  69,  64]],\n",
      "\n",
      "        [[ 72,  75,  80],\n",
      "         [ 77,  80,  87],\n",
      "         [ 82,  83,  87],\n",
      "         ...,\n",
      "         [ 71,  71,  70],\n",
      "         [ 67,  69,  68],\n",
      "         [ 67,  68,  63]],\n",
      "\n",
      "        [[ 73,  72,  75],\n",
      "         [ 79,  78,  83],\n",
      "         [ 91,  82,  79],\n",
      "         ...,\n",
      "         [ 67,  69,  66],\n",
      "         [ 66,  68,  68],\n",
      "         [ 67,  67,  64]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[118,  80,  46],\n",
      "         [114,  78,  46],\n",
      "         [112,  77,  45],\n",
      "         ...,\n",
      "         [109,  74,  40],\n",
      "         [107,  72,  38],\n",
      "         [106,  71,  37]],\n",
      "\n",
      "        [[122,  82,  45],\n",
      "         [118,  81,  46],\n",
      "         [121,  84,  48],\n",
      "         ...,\n",
      "         [114,  77,  42],\n",
      "         [113,  76,  40],\n",
      "         [115,  78,  41]],\n",
      "\n",
      "        [[123,  81,  45],\n",
      "         [119,  81,  47],\n",
      "         [120,  82,  46],\n",
      "         ...,\n",
      "         [128,  93,  60],\n",
      "         [129,  94,  61],\n",
      "         [123,  91,  58]]]], dtype=uint8)>, 'label': <tf.Tensor: shape=(16,), dtype=int64, numpy=array([7, 8, 4, 4, 6, 5, 2, 9, 6, 6, 9, 9, 3, 0, 8, 7], dtype=int64)>}\n"
     ]
    }
   ],
   "source": [
    "# Print some training data\n",
    "train_ds = data[\"train\"].batch(16)\n",
    "for item in train_ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 32, 32, 3), dtype=uint8, numpy=\n",
      "array([[[[143,  96,  70],\n",
      "         [141,  96,  72],\n",
      "         [135,  93,  72],\n",
      "         ...,\n",
      "         [ 96,  37,  19],\n",
      "         [105,  42,  18],\n",
      "         [104,  38,  20]],\n",
      "\n",
      "        [[128,  98,  92],\n",
      "         [146, 118, 112],\n",
      "         [170, 145, 138],\n",
      "         ...,\n",
      "         [108,  45,  26],\n",
      "         [112,  44,  24],\n",
      "         [112,  41,  22]],\n",
      "\n",
      "        [[ 93,  69,  75],\n",
      "         [118,  96, 101],\n",
      "         [179, 160, 162],\n",
      "         ...,\n",
      "         [128,  68,  47],\n",
      "         [125,  61,  42],\n",
      "         [122,  59,  39]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[187, 150, 123],\n",
      "         [184, 148, 123],\n",
      "         [179, 142, 121],\n",
      "         ...,\n",
      "         [198, 163, 132],\n",
      "         [201, 166, 135],\n",
      "         [207, 174, 143]],\n",
      "\n",
      "        [[187, 150, 117],\n",
      "         [181, 143, 115],\n",
      "         [175, 136, 113],\n",
      "         ...,\n",
      "         [201, 164, 132],\n",
      "         [205, 168, 135],\n",
      "         [207, 171, 139]],\n",
      "\n",
      "        [[195, 161, 126],\n",
      "         [187, 153, 123],\n",
      "         [186, 151, 128],\n",
      "         ...,\n",
      "         [212, 177, 147],\n",
      "         [219, 185, 155],\n",
      "         [221, 187, 157]]],\n",
      "\n",
      "\n",
      "       [[[203, 214, 234],\n",
      "         [191, 207, 226],\n",
      "         [178, 200, 224],\n",
      "         ...,\n",
      "         [127, 172, 213],\n",
      "         [126, 171, 212],\n",
      "         [124, 170, 211]],\n",
      "\n",
      "        [[205, 214, 230],\n",
      "         [186, 199, 213],\n",
      "         [180, 197, 214],\n",
      "         ...,\n",
      "         [132, 178, 219],\n",
      "         [130, 176, 219],\n",
      "         [129, 175, 217]],\n",
      "\n",
      "        [[193, 200, 213],\n",
      "         [141, 151, 159],\n",
      "         [124, 137, 145],\n",
      "         ...,\n",
      "         [136, 178, 218],\n",
      "         [134, 177, 218],\n",
      "         [132, 176, 217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 40,  47,  56],\n",
      "         [ 33,  37,  42],\n",
      "         [ 31,  35,  41],\n",
      "         ...,\n",
      "         [ 73,  99, 132],\n",
      "         [ 64,  91, 126],\n",
      "         [ 69,  97, 133]],\n",
      "\n",
      "        [[ 37,  44,  53],\n",
      "         [ 31,  34,  40],\n",
      "         [ 30,  34,  40],\n",
      "         ...,\n",
      "         [ 72,  98, 132],\n",
      "         [ 64,  92, 127],\n",
      "         [ 68,  96, 132]],\n",
      "\n",
      "        [[ 34,  41,  50],\n",
      "         [ 29,  32,  38],\n",
      "         [ 28,  32,  38],\n",
      "         ...,\n",
      "         [ 68,  94, 127],\n",
      "         [ 62,  89, 123],\n",
      "         [ 63,  91, 126]]],\n",
      "\n",
      "\n",
      "       [[[106, 103, 104],\n",
      "         [103,  97,  99],\n",
      "         [102,  93,  96],\n",
      "         ...,\n",
      "         [135, 126, 129],\n",
      "         [139, 130, 133],\n",
      "         [131, 122, 125]],\n",
      "\n",
      "        [[106, 104, 105],\n",
      "         [105,  99, 101],\n",
      "         [115, 106, 109],\n",
      "         ...,\n",
      "         [137, 129, 132],\n",
      "         [135, 126, 129],\n",
      "         [124, 115, 118]],\n",
      "\n",
      "        [[108, 105, 106],\n",
      "         [117, 111, 113],\n",
      "         [123, 114, 117],\n",
      "         ...,\n",
      "         [132, 123, 126],\n",
      "         [126, 117, 120],\n",
      "         [121, 112, 115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[136, 163, 117],\n",
      "         [135, 162, 115],\n",
      "         [139, 166, 117],\n",
      "         ...,\n",
      "         [140, 144, 111],\n",
      "         [133, 135, 105],\n",
      "         [126, 125,  98]],\n",
      "\n",
      "        [[130, 150, 104],\n",
      "         [131, 150, 107],\n",
      "         [131, 150, 109],\n",
      "         ...,\n",
      "         [141, 150, 112],\n",
      "         [144, 152, 115],\n",
      "         [140, 144, 111]],\n",
      "\n",
      "        [[139, 151, 108],\n",
      "         [133, 144, 103],\n",
      "         [145, 156, 116],\n",
      "         ...,\n",
      "         [129, 137, 100],\n",
      "         [138, 144, 110],\n",
      "         [134, 136, 106]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[146, 149, 166],\n",
      "         [143, 147, 164],\n",
      "         [141, 144, 160],\n",
      "         ...,\n",
      "         [215, 194, 176],\n",
      "         [225, 204, 186],\n",
      "         [224, 203, 185]],\n",
      "\n",
      "        [[143, 149, 165],\n",
      "         [143, 148, 165],\n",
      "         [140, 144, 160],\n",
      "         ...,\n",
      "         [182, 164, 149],\n",
      "         [186, 168, 153],\n",
      "         [179, 161, 146]],\n",
      "\n",
      "        [[139, 144, 163],\n",
      "         [139, 144, 162],\n",
      "         [137, 142, 160],\n",
      "         ...,\n",
      "         [183, 161, 147],\n",
      "         [187, 165, 151],\n",
      "         [186, 164, 150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 70,  70,  85],\n",
      "         [ 69,  69,  83],\n",
      "         [ 67,  67,  81],\n",
      "         ...,\n",
      "         [ 81,  83,  99],\n",
      "         [ 81,  84,  99],\n",
      "         [ 73,  75,  91]],\n",
      "\n",
      "        [[ 72,  71,  85],\n",
      "         [ 70,  69,  83],\n",
      "         [ 68,  67,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  96],\n",
      "         [ 81,  83,  98],\n",
      "         [ 73,  75,  90]],\n",
      "\n",
      "        [[ 72,  72,  85],\n",
      "         [ 70,  70,  83],\n",
      "         [ 69,  69,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  95],\n",
      "         [ 81,  83,  97],\n",
      "         [ 73,  75,  89]]],\n",
      "\n",
      "\n",
      "       [[[133, 151, 172],\n",
      "         [129, 148, 172],\n",
      "         [131, 153, 173],\n",
      "         ...,\n",
      "         [226, 221, 211],\n",
      "         [228, 224, 215],\n",
      "         [218, 213, 207]],\n",
      "\n",
      "        [[135, 152, 174],\n",
      "         [130, 148, 174],\n",
      "         [132, 152, 176],\n",
      "         ...,\n",
      "         [215, 211, 201],\n",
      "         [213, 208, 200],\n",
      "         [203, 198, 193]],\n",
      "\n",
      "        [[142, 158, 179],\n",
      "         [133, 149, 177],\n",
      "         [131, 149, 175],\n",
      "         ...,\n",
      "         [206, 201, 194],\n",
      "         [203, 199, 193],\n",
      "         [197, 192, 188]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 82,  91,  97],\n",
      "         [ 92, 105, 109],\n",
      "         [ 92, 108, 118],\n",
      "         ...,\n",
      "         [ 86, 105, 113],\n",
      "         [ 92, 109, 116],\n",
      "         [ 90, 105, 114]],\n",
      "\n",
      "        [[ 88,  93,  99],\n",
      "         [ 96, 106, 110],\n",
      "         [ 94, 108, 117],\n",
      "         ...,\n",
      "         [ 87, 103, 117],\n",
      "         [ 91, 105, 115],\n",
      "         [ 91, 103, 116]],\n",
      "\n",
      "        [[ 88,  90,  97],\n",
      "         [ 94, 100, 105],\n",
      "         [ 91,  99, 108],\n",
      "         ...,\n",
      "         [ 89, 103, 117],\n",
      "         [ 87, 100, 111],\n",
      "         [ 90, 102, 114]]],\n",
      "\n",
      "\n",
      "       [[[ 75,  75,  80],\n",
      "         [ 75,  77,  81],\n",
      "         [ 81,  83,  88],\n",
      "         ...,\n",
      "         [ 71,  72,  70],\n",
      "         [ 68,  70,  68],\n",
      "         [ 68,  69,  64]],\n",
      "\n",
      "        [[ 72,  75,  80],\n",
      "         [ 77,  80,  87],\n",
      "         [ 82,  83,  87],\n",
      "         ...,\n",
      "         [ 71,  71,  70],\n",
      "         [ 67,  69,  68],\n",
      "         [ 67,  68,  63]],\n",
      "\n",
      "        [[ 73,  72,  75],\n",
      "         [ 79,  78,  83],\n",
      "         [ 91,  82,  79],\n",
      "         ...,\n",
      "         [ 67,  69,  66],\n",
      "         [ 66,  68,  68],\n",
      "         [ 67,  67,  64]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[118,  80,  46],\n",
      "         [114,  78,  46],\n",
      "         [112,  77,  45],\n",
      "         ...,\n",
      "         [109,  74,  40],\n",
      "         [107,  72,  38],\n",
      "         [106,  71,  37]],\n",
      "\n",
      "        [[122,  82,  45],\n",
      "         [118,  81,  46],\n",
      "         [121,  84,  48],\n",
      "         ...,\n",
      "         [114,  77,  42],\n",
      "         [113,  76,  40],\n",
      "         [115,  78,  41]],\n",
      "\n",
      "        [[123,  81,  45],\n",
      "         [119,  81,  47],\n",
      "         [120,  82,  46],\n",
      "         ...,\n",
      "         [128,  93,  60],\n",
      "         [129,  94,  61],\n",
      "         [123,  91,  58]]]], dtype=uint8)>, <tf.Tensor: shape=(16, 10), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# Section 3.2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Defining a dataset with batch size 16\n",
    "train_ds = data[\"train\"].batch(16)\n",
    "\n",
    "# Creating a dataset that returns an (image, one-hot label) tuple\n",
    "def format_data(x):\n",
    "    return (x[\"image\"], tf.one_hot(x[\"label\"], depth=10))\n",
    "train_ds = train_ds.map(format_data)\n",
    "\n",
    "# Iterating the dataset\n",
    "for item in train_ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple CNN on the Cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3125/3125 [==============================] - 37s 12ms/step - loss: 3.1641 - acc: 0.1257\n",
      "Epoch 2/25\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 2.2790 - acc: 0.1293\n",
      "Epoch 3/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 2.2457 - acc: 0.1509\n",
      "Epoch 4/25\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 2.2140 - acc: 0.1586\n",
      "Epoch 5/25\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 2.1870 - acc: 0.1669\n",
      "Epoch 6/25\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 2.1570 - acc: 0.1856\n",
      "Epoch 7/25\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.1155 - acc: 0.2001\n",
      "Epoch 8/25\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0815 - acc: 0.2108\n",
      "Epoch 9/25\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 2.0614 - acc: 0.2199\n",
      "Epoch 10/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 2.0388 - acc: 0.2287\n",
      "Epoch 11/25\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0236 - acc: 0.2331\n",
      "Epoch 12/25\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9951 - acc: 0.2428\n",
      "Epoch 13/25\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9967 - acc: 0.2456\n",
      "Epoch 14/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.9828 - acc: 0.2511\n",
      "Epoch 15/25\n",
      "3125/3125 [==============================] - 25s 8ms/step - loss: 1.9680 - acc: 0.2578\n",
      "Epoch 16/25\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 1.9813 - acc: 0.2526\n",
      "Epoch 17/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.9416 - acc: 0.2674\n",
      "Epoch 18/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.9393 - acc: 0.2678\n",
      "Epoch 19/25\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.9709 - acc: 0.2680\n",
      "Epoch 20/25\n",
      "3125/3125 [==============================] - 24s 8ms/step - loss: 1.9402 - acc: 0.2726\n",
      "Epoch 21/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.9265 - acc: 0.2748\n",
      "Epoch 22/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.9036 - acc: 0.2801\n",
      "Epoch 23/25\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.9050 - acc: 0.2819\n",
      "Epoch 24/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.9075 - acc: 0.2837\n",
      "Epoch 25/25\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.8830 - acc: 0.2901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x283a722bdd8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Section 3.2\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Defining a simple convolution neural network to process the CIFAR data\n",
    "model = Sequential([\n",
    "    Conv2D(64,(5,5), activation='relu', input_shape=(32,32,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# Fitting the model on the data for 25 epochs\n",
    "model.fit(train_ds, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
